{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEN122A Statistical Analysis of Choice Behaviour \n",
    "\n",
    "## `Session Lab 03 EXTRA:`\n",
    "## `Combining machine learning and discrete choice models`\n",
    "\n",
    "**Delft University of Technology**<br>\n",
    "**Q2 2024**<br>\n",
    "**Instructor:** Sander van Cranenburgh<br>\n",
    "**TA:**  Gabriel Nova <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Instructions`\n",
    "\n",
    "**Lab sessions aim to:**<br>\n",
    "* Show and reinforce how models and ideas presented in class are put to practice.<br>\n",
    "* Help you gather hands-on machine learning skills.<br>\n",
    "\n",
    "**Lab sessions are:**<br>\n",
    "* Learning environments where you work with Jupyter notebooks and where you can get support from TAs and fellow students.<br> \n",
    "* Not graded and do not have to be submitted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Application: Modelling neighbourhood choices`\n",
    "\n",
    "In this lab session, we will use neighbourhood location choice data of lab session 1: Stated Choice (SC) data, which was collected between 2017 and 2018 in four European cities: Hanover, Mainz, Bern, and Zurich. During this lab session, you will train a neural network and a hybrid choices model to uncover people's preferences over residential location choice attributes, such as the distance to the city centre and the share of foreigners in their neighbourhood. \n",
    "\n",
    "![sc](data/sc_experiment.png)\n",
    "\n",
    "\n",
    "This time the emphesize is on the balance that the researcher must strike between behavioural rigour and model fit.\n",
    "To do so, in this lab session you will (1) develop a multilayer perceptron model and (2) build a hybrid choice models.\n",
    "\n",
    "**`Learning objectives lab session 03`**\n",
    "\n",
    "After completing the following lab session you will be able to:\n",
    "* Train a hybrid choice model, using PyTorch\n",
    "* Strike a balance between behavioural rigour and model fit\n",
    "* Reflect on the strength and weaknesses of both data and theory-driven modelling approaches\n",
    "\n",
    "\n",
    "**`This lab consists of 1 part and has 2 exercises`**\n",
    "\n",
    "**Part 1**: The L-MNL model\n",
    "- Excerise 1: \"Features in MLP of LMNL model\"\n",
    "- Excerise 2: \"Forecasting using L-MNL model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Import packages`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biogeme\n",
    "import biogeme.database as db\n",
    "import biogeme.biogeme as bio\n",
    "from biogeme import models\n",
    "from biogeme.expressions import Beta, Variable, log\n",
    "\n",
    "# Import required Python packages and modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Import custom functions\n",
    "from train_functions import show_loss_plot, print_model_summary, evaluate_lmnl\n",
    "\n",
    "# Pandas setting to show all columns when displaying a pandas dataframe\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: The L-MNL model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `1. Load the data set prepared in Lab 03` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CHOICE</th>\n",
       "      <th>STORES1</th>\n",
       "      <th>TRANSPORT1</th>\n",
       "      <th>CITY1</th>\n",
       "      <th>NOISE1</th>\n",
       "      <th>GREEN1</th>\n",
       "      <th>FOREIGN1</th>\n",
       "      <th>STORES2</th>\n",
       "      <th>TRANSPORT2</th>\n",
       "      <th>CITY2</th>\n",
       "      <th>NOISE2</th>\n",
       "      <th>GREEN2</th>\n",
       "      <th>FOREIGN2</th>\n",
       "      <th>STORES3</th>\n",
       "      <th>TRANSPORT3</th>\n",
       "      <th>CITY3</th>\n",
       "      <th>NOISE3</th>\n",
       "      <th>GREEN3</th>\n",
       "      <th>FOREIGN3</th>\n",
       "      <th>AGE_2</th>\n",
       "      <th>AGE_3</th>\n",
       "      <th>WOMAN_1</th>\n",
       "      <th>HOMEOWNER_1</th>\n",
       "      <th>CAROWNER_1</th>\n",
       "      <th>RESPCITY_2</th>\n",
       "      <th>RESPCITY_3</th>\n",
       "      <th>RESPCITY_4</th>\n",
       "      <th>JOB_1</th>\n",
       "      <th>ENVCONC_2</th>\n",
       "      <th>ENVCONC_3</th>\n",
       "      <th>ENVCONC_4</th>\n",
       "      <th>ENVCONC_5</th>\n",
       "      <th>EDUYEARS_9</th>\n",
       "      <th>EDUYEARS_10</th>\n",
       "      <th>EDUYEARS_11</th>\n",
       "      <th>EDUYEARS_12</th>\n",
       "      <th>EDUYEARS_13</th>\n",
       "      <th>EDUYEARS_14</th>\n",
       "      <th>EDUYEARS_15</th>\n",
       "      <th>EDUYEARS_16</th>\n",
       "      <th>EDUYEARS_17</th>\n",
       "      <th>EDUYEARS_18</th>\n",
       "      <th>RESPFOREIGN_1</th>\n",
       "      <th>NONWESTERN_1</th>\n",
       "      <th>WESTERN_1</th>\n",
       "      <th>draw</th>\n",
       "      <th>train_set</th>\n",
       "      <th>test_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.543405</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.543405</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.543405</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.543405</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278369</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  CHOICE  STORES1  TRANSPORT1  CITY1  NOISE1  GREEN1  FOREIGN1  STORES2  \\\n",
       "0   2       1       10           5      1       2       2       0.4       15   \n",
       "1   2       2       15           5      4       4       1       0.1        2   \n",
       "2   2       3       10          15      1       3       1       0.4       15   \n",
       "3   2       2       15          15      5       4       4       0.4        2   \n",
       "4   3       2       15           5      5       1       3       0.4        2   \n",
       "\n",
       "   TRANSPORT2  CITY2  NOISE2  GREEN2  FOREIGN2  STORES3  TRANSPORT3  CITY3  \\\n",
       "0          10      2       3       3       0.1        2          15      4   \n",
       "1          10      5       1       2       0.2        5          15      1   \n",
       "2           2      2       4       2       0.1        2           5      4   \n",
       "3           2      1       1       1       0.1        5           5      2   \n",
       "4          10      1       2       4       0.1        5          15      2   \n",
       "\n",
       "   NOISE3  GREEN3  FOREIGN3  AGE_2  AGE_3  WOMAN_1  HOMEOWNER_1  CAROWNER_1  \\\n",
       "0       4       4       0.2      1      0        0            0           0   \n",
       "1       2       3       0.3      1      0        0            0           0   \n",
       "2       1       3       0.2      1      0        0            0           0   \n",
       "3       2       2       0.2      1      0        0            0           0   \n",
       "4       3       1       0.2      1      0        1            0           1   \n",
       "\n",
       "   RESPCITY_2  RESPCITY_3  RESPCITY_4  JOB_1  ENVCONC_2  ENVCONC_3  ENVCONC_4  \\\n",
       "0           0           1           0      0          0          1          0   \n",
       "1           0           1           0      0          0          1          0   \n",
       "2           0           1           0      0          0          1          0   \n",
       "3           0           1           0      0          0          1          0   \n",
       "4           1           0           0      1          0          0          1   \n",
       "\n",
       "   ENVCONC_5  EDUYEARS_9  EDUYEARS_10  EDUYEARS_11  EDUYEARS_12  EDUYEARS_13  \\\n",
       "0          0           0            0            0            0            0   \n",
       "1          0           0            0            0            0            0   \n",
       "2          0           0            0            0            0            0   \n",
       "3          0           0            0            0            0            0   \n",
       "4          0           0            0            0            0            0   \n",
       "\n",
       "   EDUYEARS_14  EDUYEARS_15  EDUYEARS_16  EDUYEARS_17  EDUYEARS_18  \\\n",
       "0            0            0            0            0            1   \n",
       "1            0            0            0            0            1   \n",
       "2            0            0            0            0            1   \n",
       "3            0            0            0            0            1   \n",
       "4            0            0            0            1            0   \n",
       "\n",
       "   RESPFOREIGN_1  NONWESTERN_1  WESTERN_1      draw  train_set  test_set  \n",
       "0              0             0          0  0.543405       True     False  \n",
       "1              0             0          0  0.543405       True     False  \n",
       "2              0             0          0  0.543405       True     False  \n",
       "3              0             0          0  0.543405       True     False  \n",
       "4              1             0          0  0.278369       True     False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create that path to the data file\n",
    "data_path = Path(f'data/choice_data_cleaned_lab3E.dat')\n",
    "\n",
    "# Load mode choice data into a pandas DataFrame\n",
    "df = pd.read_csv(data_path, sep='\\t')\n",
    "\n",
    "# Define the relevant features of the alternatives\n",
    "features_alt =   ['STORES1', 'TRANSPORT1', 'CITY1', 'NOISE1', 'GREEN1', 'FOREIGN1', \n",
    "                  'STORES2', 'TRANSPORT2', 'CITY2', 'NOISE2', 'GREEN2', 'FOREIGN2',\n",
    "                  'STORES3', 'TRANSPORT3', 'CITY3', 'NOISE3', 'GREEN3', 'FOREIGN3']\n",
    "\n",
    "# Define the relevant socio-economic variables\n",
    "features_socio = ['AGE_2','AGE_3','WOMAN_1','HOMEOWNER_1','CAROWNER_1','RESPCITY_2','RESPCITY_3','RESPCITY_4','JOB_1','NONWESTERN_1','WESTERN_1']\n",
    "\n",
    "# Show the first few rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of individuals in the df_train and df_test: \t1825  423 \n",
      "Number of observations in the df_train and df_test: \t7300 1692 \n"
     ]
    }
   ],
   "source": [
    "# Reconstruct the test and training sets\n",
    "df_train = df.loc[df['train_set'] == True,:].copy()\n",
    "df_test  = df.loc[df['test_set'] == True,:].copy()\n",
    "\n",
    "# Number of observations in the training and test sets\n",
    "num_obs_train = len(df_train)\n",
    "num_obs_test  = len(df_test)\n",
    "\n",
    "print(f'Number of individuals in the df_train and df_test: \\t{df_train.ID.nunique()}  {df_test.ID.nunique()} ')\n",
    "print(f'Number of observations in the df_train and df_test: \\t{len(df_train)} {len(df_test)} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To efficiently train MLPs it strongly recommended to scale (a.k.a. normalise) the features. We use sk-learn's 'StandardScaler'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train (7300, 21)\n",
      "Shape of x_test (1692, 21)\n"
     ]
    }
   ],
   "source": [
    "# Create X_train and X_test\n",
    "x_train = df_train[features_alt + features_socio]\n",
    "x_test  = df_test [features_alt + features_socio]\n",
    "\n",
    "# Initialize the scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "scaler = scaler.fit(df[features_alt + features_socio])\n",
    "\n",
    "# Apply the fitted scaler to the  data sets\n",
    "x_train_scaled = pd.DataFrame(scaler.transform(df_train[features_alt + features_socio]), columns=[features_alt + features_socio])\n",
    "x_test_scaled =  pd.DataFrame(scaler.transform(df_test [features_alt + features_socio]), columns=[features_alt + features_socio]) # Apply the fitted scaler to the test data\n",
    "\n",
    "print('Shape of x_train', x_train_scaled.shape)\n",
    "print('Shape of x_test', x_test_scaled.shape)\n",
    "\n",
    "# Create the target values\n",
    "# Y must be a dummy coded array\n",
    "y_train_dummy = pd.get_dummies(df_train['CHOICE']).values.astype(int)\n",
    "y_test_dummy = pd.get_dummies(df_test['CHOICE']).values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `The L-MNL model `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will build and train a hybrid model, namely the L-MNL model. This model combines an interpretable part following the assumptions of the MNL model and a neural network that processes the rest of the variables that we do not want to interpret. More specifically, we want the **flexibility** of the MLP but still want to get out an **estimate of the willingness to pay to reduce the walking distance to the grocery stores, expressed in terms of distance to the public transport**.\n",
    "\n",
    "The figure below conceptually shows this model:<br>\n",
    "\n",
    "<p align=\"center\">\n",
    "<img width=\"600\" src=\"assets/hybrid_model.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`i. Define the L-MNL model`<br>\n",
    "To create the L-MNL model,we create a new class using PyTorch's nn.Module. <br>\n",
    "* The MNL part is implemented with separate linear layers for features (transport and foreign), allowing the utility to be calculated for each alternative. <br>\n",
    "* The MLP part consists of two hidden layers (linear1 and linear2) with a given number of neurons.<br>\n",
    "* The forward function takes `x_mnl` and `x_mlp` as inputs. x_mlp is passed through the network layers, while applying activation functions. It outputs the utilities of each alternative `V_MLP`. x_mnl is used to compute utilities in a linear-additive fashion. \n",
    "* Finally, the utilities of boths parts are summed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMNL(nn.Module):\n",
    "    def __init__(self, input_size_mlp, hidden_size1, hidden_size2,output_size):\n",
    "        super(LMNL,self).__init__()\n",
    "\n",
    "        # Create betas for the MNL part\n",
    "        self.B_transport = nn.Linear(1, 1, bias=False )\n",
    "        self.B_stores   = nn.Linear(1, 1, bias=False )\n",
    "                                 \n",
    "        # Create the hidden layers for the MLP part\n",
    "        self.linear1 = nn.Linear(input_size_mlp, hidden_size1, bias=False)\n",
    "        self.linear2 = nn.Linear(hidden_size1,   hidden_size2, bias=False) \n",
    "        self.linear3 = nn.Linear(hidden_size2,   output_size,  bias=False) \n",
    "\n",
    "    def forward(self, X_MNL, X_MLP):\n",
    "        \n",
    "        # Utility functions for the MNL part \n",
    "        V_A = self.B_transport(X_MNL[:,0].unsqueeze(1))  + self.B_stores(X_MNL[:,1].unsqueeze(1))\n",
    "        V_B = self.B_transport(X_MNL[:,2].unsqueeze(1))  + self.B_stores(X_MNL[:,3].unsqueeze(1))\n",
    "        V_C = self.B_transport(X_MNL[:,4].unsqueeze(1))  + self.B_stores(X_MNL[:,5].unsqueeze(1))\n",
    "                     \n",
    "        # Concatenating tensors to maintain the output dimension\n",
    "        V_MNL = torch.cat((V_A, V_B, V_C), dim=1)\n",
    "\n",
    "        # The MLP part\n",
    "        X_MLP = torch.tanh(self.linear1(X_MLP)) # tanh activation function for the 1st layer\n",
    "        X_MLP = torch.tanh(self.linear2(X_MLP)) # tanh activation function for the 2nd layer\n",
    "        V_MLP = self.linear3(X_MLP)             # linear activation function for the output layer\n",
    "\n",
    "        # Sum the utilities from the MNL and MLP parts\n",
    "        V = V_MNL + V_MLP\n",
    "        return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ii. Prepare the data for training the L-MNL model`<br>\n",
    "We need to split the features going into the MLP and MNL parts. Because we want to compute the WTP of stores over transport. Therefore, the features related to transport and stores go into the MNL part, while the other features, including socio-demographics, go into the MLP part. **Importantly**, the MNL features must NOT be scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_mnl_train\t (7300, 6)\n",
      "Shape of x_mnl_test\t (1692, 6)\n",
      "\n",
      "Shape of x_mlp_train\t (7300, 15)\n",
      "Shape of x_mlp_test\t (1692, 15)\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe with features for MNL part\n",
    "features_mnl = ['TRANSPORT1', 'STORES1','TRANSPORT2', 'STORES2','TRANSPORT3', 'STORES3']\n",
    "x_mnl_train = x_train[features_mnl]\n",
    "x_mnl_test  = x_test[features_mnl]\n",
    "\n",
    "print('Shape of x_mnl_train\\t', x_mnl_train.shape)\n",
    "print('Shape of x_mnl_test\\t', x_mnl_test.shape)\n",
    "\n",
    "# Create dataframe with features for MLP part\n",
    "features_mlp_alt = ['FOREIGN1', 'CITY1', 'NOISE1', 'GREEN1', \n",
    "                    'FOREIGN2', 'CITY2', 'NOISE2', 'GREEN2', \n",
    "                    'FOREIGN3', 'CITY3', 'NOISE3', 'GREEN3']\n",
    "\n",
    "\n",
    "features_socio = ['RESPCITY_2','RESPCITY_3','RESPCITY_4']\n",
    "x_mlp_train = x_train_scaled[features_mlp_alt + features_socio]\n",
    "x_mlp_test  = x_test_scaled[features_mlp_alt + features_socio]\n",
    "\n",
    "print('\\nShape of x_mlp_train\\t', x_mlp_train.shape)\n",
    "print('Shape of x_mlp_test\\t', x_mlp_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data to PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the X_mnl_train tensor =  torch.Size([7300, 6])\n",
      "Size of the X_mlp_train tensor =  torch.Size([7300, 15])\n",
      "\n",
      "Size of the X_mnl_test tensor  =  torch.Size([1692, 6])\n",
      "Size of the X_mlp_test tensor  =  torch.Size([1692, 15])\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "x_mnl_train_tensor = torch.tensor(x_mnl_train.values, dtype=torch.float)\n",
    "x_mlp_train_tensor = torch.tensor(x_mlp_train.values, dtype=torch.float)\n",
    "y_train_dummy_tensor = torch.tensor(y_train_dummy,    dtype=torch.float)\n",
    "\n",
    "# test\n",
    "x_mnl_test_tensor = torch.tensor(x_mnl_test.values, dtype=torch.float)\n",
    "x_mlp_test_tensor = torch.tensor(x_mlp_test.values, dtype=torch.float)\n",
    "y_test_dummy_tensor = torch.tensor(y_test_dummy,    dtype=torch.float)\n",
    "\n",
    "print('Size of the X_mnl_train tensor = ', x_mnl_train_tensor.size())\n",
    "print('Size of the X_mlp_train tensor = ', x_mlp_train_tensor.size())\n",
    "print('\\nSize of the X_mnl_test tensor  = ', x_mnl_test_tensor.size())\n",
    "print('Size of the X_mlp_test tensor  = ', x_mlp_test_tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create PyTorch DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader for the train set\n",
    "dataset_train_lmnl = TensorDataset(x_mnl_train_tensor, x_mlp_train_tensor, y_train_dummy_tensor)\n",
    "train_loader_lmnl = DataLoader(dataset_train_lmnl, batch_size=250, shuffle=True)\n",
    "\n",
    "# Create a DataLoader for the test set\n",
    "dataset_test_lmnl = TensorDataset(x_mnl_test_tensor, x_mlp_test_tensor, y_test_dummy_tensor)\n",
    "test_loader_lmnl = DataLoader(dataset_test_lmnl, batch_size=len(x_mnl_test_tensor), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iv. Create the L-MNL model object`<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input_size_mnl = 6, input_size_mlp = 15, hidden_size1 = 10, hidden_size2 = 10, output_size = 3\n"
     ]
    }
   ],
   "source": [
    "# Define the dimensions\n",
    "input_size_mnl = x_mnl_train_tensor.size()[1]  # Number of input features\n",
    "input_size_mlp = x_mlp_train_tensor.size()[1]  # Number of input features\n",
    "hidden_size1 = 10  # Number of units in first hidden layer\n",
    "hidden_size2 = 10  # Number of units in second hidden layer\n",
    "output_size = 3    # Number of output classes\n",
    "print(f' input_size_mnl = {input_size_mnl}, input_size_mlp = {input_size_mlp}, hidden_size1 = {hidden_size1}, hidden_size2 = {hidden_size2}, output_size = {output_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Summary ===\n",
      "Layer: B_transport.weight  |\t Weights: 1\n",
      "Layer: B_stores.weight     |\t Weights: 1\n",
      "Layer: linear1.weight      |\t Weights: 150\n",
      "Layer: linear2.weight      |\t Weights: 100\n",
      "Layer: linear3.weight      |\t Weights: 30\n",
      "\n",
      "Total trainable Weights: 282\n",
      "\n",
      "=== Layers ===\n",
      "Linear(in_features=1, out_features=1, bias=False)\n",
      "Linear(in_features=1, out_features=1, bias=False)\n",
      "Linear(in_features=15, out_features=10, bias=False)\n",
      "Linear(in_features=10, out_features=10, bias=False)\n",
      "Linear(in_features=10, out_features=3, bias=False)\n"
     ]
    }
   ],
   "source": [
    "# Invoke the L-MNL model\n",
    "model = LMNL(input_size_mlp, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Print the model architecture\n",
    "print_model_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`v. Train the L-MNL model`<br>\n",
    "Finally, we are ready to train the L-MNL model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training settings\n",
    "nEpoch = 1000  # Set the number of epochs\n",
    "lr = 0.0001  # Set the learning rate\n",
    "status = 10  # Print status every 'status' epochs\n",
    "patience = 5  # Number of epochs to wait before early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [    1/1000], Train Loss: 29164.037, Test Loss: 6632.326\n",
      "Epoch [   10/1000], Train Loss: 27861.080, Test Loss: 6323.301\n",
      "Epoch [   20/1000], Train Loss: 26280.344, Test Loss: 5947.205\n",
      "Epoch [   30/1000], Train Loss: 24356.929, Test Loss: 5483.187\n",
      "Epoch [   40/1000], Train Loss: 22124.882, Test Loss: 4938.949\n",
      "Epoch [   50/1000], Train Loss: 20044.212, Test Loss: 4433.990\n",
      "Epoch [   60/1000], Train Loss: 18431.751, Test Loss: 4051.990\n",
      "Epoch [   70/1000], Train Loss: 17109.551, Test Loss: 3750.984\n",
      "Epoch [   80/1000], Train Loss: 15855.410, Test Loss: 3478.107\n",
      "Epoch [   90/1000], Train Loss: 14650.565, Test Loss: 3220.606\n",
      "Epoch [  100/1000], Train Loss: 13560.873, Test Loss: 2983.582\n",
      "Epoch [  110/1000], Train Loss: 12576.116, Test Loss: 2764.767\n",
      "Epoch [  120/1000], Train Loss: 11665.911, Test Loss: 2560.420\n",
      "Epoch [  130/1000], Train Loss: 10830.086, Test Loss: 2371.562\n",
      "Epoch [  140/1000], Train Loss: 10082.933, Test Loss: 2203.580\n",
      "Epoch [  150/1000], Train Loss: 9435.350, Test Loss: 2059.242\n",
      "Epoch [  160/1000], Train Loss: 8891.396, Test Loss: 1939.040\n",
      "Epoch [  170/1000], Train Loss: 8442.818, Test Loss: 1840.705\n",
      "Epoch [  180/1000], Train Loss: 8074.704, Test Loss: 1760.843\n",
      "Epoch [  190/1000], Train Loss: 7770.767, Test Loss: 1695.767\n",
      "Epoch [  200/1000], Train Loss: 7519.370, Test Loss: 1643.097\n",
      "Epoch [  210/1000], Train Loss: 7310.407, Test Loss: 1600.097\n",
      "Epoch [  220/1000], Train Loss: 7134.645, Test Loss: 1564.628\n",
      "Epoch [  230/1000], Train Loss: 6985.536, Test Loss: 1535.390\n",
      "Epoch [  240/1000], Train Loss: 6857.044, Test Loss: 1510.988\n",
      "Epoch [  250/1000], Train Loss: 6744.875, Test Loss: 1489.925\n",
      "Epoch [  260/1000], Train Loss: 6645.418, Test Loss: 1471.956\n",
      "Epoch [  270/1000], Train Loss: 6557.209, Test Loss: 1456.449\n",
      "Epoch [  280/1000], Train Loss: 6480.100, Test Loss: 1443.153\n",
      "Epoch [  290/1000], Train Loss: 6413.211, Test Loss: 1432.198\n",
      "Epoch [  300/1000], Train Loss: 6356.318, Test Loss: 1423.260\n",
      "Epoch [  310/1000], Train Loss: 6308.257, Test Loss: 1416.229\n",
      "Epoch [  320/1000], Train Loss: 6269.097, Test Loss: 1410.514\n",
      "Epoch [  330/1000], Train Loss: 6237.052, Test Loss: 1406.233\n",
      "Epoch [  340/1000], Train Loss: 6210.203, Test Loss: 1402.760\n",
      "Epoch [  350/1000], Train Loss: 6188.139, Test Loss: 1400.317\n",
      "Epoch [  360/1000], Train Loss: 6169.742, Test Loss: 1398.030\n",
      "Epoch [  370/1000], Train Loss: 6154.617, Test Loss: 1396.076\n",
      "Epoch [  380/1000], Train Loss: 6141.600, Test Loss: 1394.727\n",
      "Epoch [  390/1000], Train Loss: 6130.201, Test Loss: 1393.548\n",
      "Epoch [  400/1000], Train Loss: 6120.543, Test Loss: 1392.434\n",
      "Epoch [  410/1000], Train Loss: 6112.003, Test Loss: 1391.310\n",
      "Epoch [  420/1000], Train Loss: 6104.862, Test Loss: 1390.410\n",
      "Epoch [  430/1000], Train Loss: 6097.989, Test Loss: 1389.723\n",
      "Epoch [  440/1000], Train Loss: 6092.060, Test Loss: 1389.057\n",
      "Epoch [  450/1000], Train Loss: 6086.913, Test Loss: 1388.469\n",
      "Epoch [  460/1000], Train Loss: 6082.081, Test Loss: 1387.920\n",
      "Epoch [  470/1000], Train Loss: 6078.031, Test Loss: 1387.360\n",
      "Epoch [  480/1000], Train Loss: 6073.998, Test Loss: 1386.964\n",
      "Epoch [  490/1000], Train Loss: 6070.797, Test Loss: 1386.527\n",
      "Epoch [  500/1000], Train Loss: 6067.489, Test Loss: 1386.019\n",
      "Epoch [  510/1000], Train Loss: 6064.862, Test Loss: 1385.735\n",
      "Epoch [  520/1000], Train Loss: 6062.000, Test Loss: 1385.548\n",
      "Epoch [  530/1000], Train Loss: 6059.480, Test Loss: 1385.381\n",
      "Early stopping at epoch 533\n",
      "\n",
      "Training finished.\tTrain Loss: 6059.340, Test Loss: 1385.203\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAINCAYAAAAtJ/ceAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABsuUlEQVR4nO3dd5wU9f3H8dfs9X60a3A06e0oAgKCBRRQEbAbDGgsUSFKLFGSnyVqginWaKxRYtRgUEFEEQHpIL33cnCUO452ve/O74+5W1g4Djjubnbv3s/HYx4zO9/Z2c+yat758p3v1zBN00RERERExAc57C5ARERERKSyFGZFRERExGcpzIqIiIiIz1KYFRERERGfpTArIiIiIj5LYVZEREREfJbCrIiIiIj4LIVZEREREfFZ/nYXUNNcLheHDh0iIiICwzDsLkdERERETmOaJtnZ2SQkJOBwVNz3WufC7KFDh0hMTLS7DBERERE5h/3799OkSZMKr6lzYTYiIgKw/nAiIyNtrkZERERETpeVlUViYqI7t1WkzoXZsqEFkZGRCrMiIiIiXux8hoTqATARERER8VkKsyIiIiLisxRmRURERMRn1bkxsyIiIlL9nE4nxcXFdpchXiwgIAA/P7+Lvo/CrIiIiFSpnJwcDhw4gGmadpciXswwDJo0aUJ4ePhF3UdhVkRERKqM0+nkwIEDhIaG0qhRIy1QJOUyTZMjR45w4MABWrdufVE9tAqzIiIiUmWKi4sxTZNGjRoREhJidznixRo1asTevXspLi6+qDCrB8BERESkyqlHVs6lqv4ZUZgVEREREZ+lMCsiIiJSDZo3b87rr79+3tfPnz8fwzDIyMiotppqI4VZERERqdMMw6hwe/755yt135UrV/LAAw+c9/V9+/YlNTWVqKioSn3e+aptoVkPgImIiEidlpqa6j7+4osvePbZZ9m+fbv73KlTR5mmidPpxN//3BGqUaNGF1RHYGAgcXFxF/QeUc+siIiI1HFxcXHuLSoqCsMw3K+3bdtGREQEM2fOpEePHgQFBbF48WJ2797N8OHDiY2NJTw8nJ49ezJnzhyP+54+zMAwDD788ENGjhxJaGgorVu3Zvr06e7203tMJ02aRHR0NLNmzaJ9+/aEh4czZMgQj/BdUlLCI488QnR0NA0aNOCpp55izJgxjBgxotJ/HidOnGD06NHUq1eP0NBQhg4dys6dO93t+/btY9iwYdSrV4+wsDA6duzI999/737vqFGj3LNZtG7dmo8//rjStZwPrwmzL7/8MoZhMH78+AqvmzJlCu3atSM4OJjOnTu7//BERETE+5imSV5RiS1bVS7a8PTTT/Pyyy+zdetWunTpQk5ODtdddx1z585l7dq1DBkyhGHDhpGSklLhff74xz9y2223sWHDBq677jpGjRrF8ePHz3p9Xl4ef//73/nPf/7DwoULSUlJ4YknnnC3/+Uvf+Gzzz7j448/ZsmSJWRlZTFt2rSL+q533303q1atYvr06SxbtgzTNLnuuuvcK7qNHTuWwsJCFi5cyMaNG/nLX/7i7r1+5pln2LJlCzNnzmTr1q288847NGzY8KLqORevGGawcuVK3nvvPbp06VLhdUuXLuXOO+9k4sSJ3HDDDXz++eeMGDGCNWvW0KlTpxqqVkRERM5XfrGTDs/OsuWzt7wwmNDAqok6L7zwAtdcc437df369UlKSnK/fvHFF5k6dSrTp09n3LhxZ73P3XffzZ133gnAn//8Z958801WrFjBkCFDyr2+uLiYd999l0suuQSAcePG8cILL7jb//GPfzBhwgRGjhwJwFtvvXVRHX07d+5k+vTpLFmyhL59+wLw2WefkZiYyLRp07j11ltJSUnh5ptvpnPnzgC0bNnS/f6UlBS6devGpZdeCli909XN9p7ZnJwcRo0axQcffEC9evUqvPaNN95gyJAhPPnkk7Rv354XX3yR7t2789Zbb9VQtSIiIlIXlYWzMjk5OTzxxBO0b9+e6OhowsPD2bp16zl7Zk/tuAsLCyMyMpL09PSzXh8aGuoOsgDx8fHu6zMzMzl8+DC9evVyt/v5+dGjR48L+m6n2rp1K/7+/vTu3dt9rkGDBrRt25atW7cC8Mgjj/DSSy/Rr18/nnvuOTZs2OC+9qGHHmLy5Ml07dqV3/3udyxdurTStZwv23tmx44dy/XXX8+gQYN46aWXKrx22bJlPPbYYx7nBg8eXGF3emFhIYWFhe7XWVlZF1XvhcrML+abdQe5tkMccVHBNfrZIiIidgsJ8GPLC4Nt++yqEhYW5vH6iSeeYPbs2fz973+nVatWhISEcMstt1BUVFThfQICAjxeG4aBy+W6oOurcvhEZdx3330MHjyY7777jh9//JGJEyfyyiuv8Jvf/IahQ4eyb98+vv/+e2bPns3AgQMZO3Ysf//736utHlt7ZidPnsyaNWuYOHHieV2flpZGbGysx7nY2FjS0tLO+p6JEycSFRXl3hITEy+q5gs17vM1PPvNZv63an+Nfq6IiIg3MAyD0EB/W7bqXIVsyZIl3H333YwcOZLOnTsTFxfH3r17q+3zyhMVFUVsbCwrV650n3M6naxZs6bS92zfvj0lJSUsX77cfe7YsWNs376dDh06uM8lJiby4IMP8vXXX/P444/zwQcfuNsaNWrEmDFj+PTTT3n99dd5//33K13P+bCtZ3b//v08+uijzJ49m+Dg6uuxnDBhgkdvblZWVo0G2pu7N2HRzqNMXpHC2Kta4efQ8n4iIiK+rnXr1nz99dcMGzYMwzB45plnKuxhrS6/+c1vmDhxIq1ataJdu3b84x//4MSJE+cV5Ddu3EhERIT7tWEYJCUlMXz4cO6//37ee+89IiIiePrpp2ncuDHDhw8HYPz48QwdOpQ2bdpw4sQJ5s2bR/v27QF49tln6dGjBx07dqSwsJAZM2a426qLbWF29erVpKen0717d/c5p9PJwoULeeuttygsLMTPz/OvB+Li4jh8+LDHucOHD1c4J1tQUBBBQUFVW/wFGNIpjuhvAziUWcDCHUe4ql2MbbWIiIhI1Xj11Vf51a9+Rd++fWnYsCFPPfVUjQ9lBHjqqadIS0tj9OjR+Pn58cADDzB48OAzMlR5BgwY4PHaz8+PkpISPv74Yx599FFuuOEGioqKGDBgAN9//717yIPT6WTs2LEcOHCAyMhIhgwZwmuvvQZYc+VOmDCBvXv3EhISQv/+/Zk8eXLVf/FTGKZNAy+ys7PZt2+fx7l77rmHdu3a8dRTT5U7O8Htt99OXl4e3377rftc37596dKlC+++++55fW5WVhZRUVFkZmYSGRl5cV/iPL04Ywv/WpzMNR1i+WD0ped+g4iIiI8qKCggOTmZFi1aVOvfvEr5XC4X7du357bbbuPFF1+0u5wKVfTPyoXkNdt6ZiMiIs4IrGFhYTRo0MB9fvTo0TRu3Ng9pvbRRx/liiuu4JVXXuH6669n8uTJrFq1qtrHYlysO3sl8q/Fyfy0LZ20zAI9CCYiIiJVYt++ffz4449cccUVFBYW8tZbb5GcnMwvfvELu0urMbZPzVWRlJQUj1Uu+vbty+eff877779PUlISX375JdOmTfP6OWZbxUTQq3l9nC5TD4KJiIhIlXE4HEyaNImePXvSr18/Nm7cyJw5c6p9nKo3sW2YgV3sGGYAMHXtAX77xXoaR4ew8HdX6UEwERGplTTMQM5XVQ0z8Oqe2dpkaKd4okICOJiRz8KdR+wuR0RERKRWUJitIcEBftzcvQkA/11e8eogIiIiInJ+FGarW/ZhWPwanNjHnb2s+W3nbkvncFaBzYWJiIiI+D6F2eo27SGY8zys/ZTWsRH0bF7PehBspR4EExEREblYCrPVrdtd1n7tp+As4c5eTQGYvHI/TledevZOREREpMopzFa3dtdDSH3IPgS753Jd55MPgi3Sg2AiIiIiF0Vhtrr5B0HSndbxmk8IDvDjpu6NAfjvCj0IJiIiInIxFGZrQvfR1n77TMg+7B5qMGerHgQTERGxm2EYFW7PP//8Rd172rRpVXadnElhtibEtIPE3mA6Yd1ntImN4NJm1oNgU7QimIiIiK1SU1Pd2+uvv05kZKTHuSeeeMLuEqUCCrM1pax3ds0nYJru3tn/rtiPSw+CiYiI2CYuLs69RUVFYRiGx7nJkyfTvn17goODadeuHf/85z/d7y0qKmLcuHHEx8cTHBxMs2bNmDhxIgDNmzcHYOTIkRiG4X59oVwuFy+88AJNmjQhKCiIrl278sMPP5xXDaZp8vzzz9O0aVOCgoJISEjgkUceqdwflJfyt7uAOqPDCJj5NJxIhr2Lub5LX/747WbrQbBdR7miTSO7KxQREal6pgnFefZ8dkAoGBe3fPxnn33Gs88+y1tvvUW3bt1Yu3Yt999/P2FhYYwZM4Y333yT6dOn87///Y+mTZuyf/9+9u+3/tZ15cqVxMTE8PHHHzNkyBD8/PwqVcMbb7zBK6+8wnvvvUe3bt346KOPuPHGG9m8eTOtW7eusIavvvqK1157jcmTJ9OxY0fS0tJYv379Rf2ZeBuF2ZoSFA6db4bVk6wHwVr056buTZi0dC//XZ6iMCsiIrVTcR78OcGez/79IQgMu6hbPPfcc7zyyivcdNNNALRo0YItW7bw3nvvMWbMGFJSUmjdujWXX345hmHQrFkz93sbNbL+tz06Opq4uLhK1/D3v/+dp556ijvuuAOAv/zlL8ybN4/XX3+dt99+u8IaUlJSiIuLY9CgQQQEBNC0aVN69epV6Vq8kYYZ1KTuY6z9lm8g77h7qMHsrYdJ14NgIiIiXiU3N5fdu3dz7733Eh4e7t5eeukldu/eDcDdd9/NunXraNu2LY888gg//vhjldaQlZXFoUOH6Nevn8f5fv36sXXr1nPWcOutt5Kfn0/Lli25//77mTp1KiUlJVVao93UM1uTErpBbGc4vBE2TqFt71/To1k9Vu87wZTVBxh7VSu7KxQREalaAaFWD6ldn30RcnJyAPjggw/o3bu3R1vZkIHu3buTnJzMzJkzmTNnDrfddhuDBg3iyy+/vKjPvhAV1ZCYmMj27duZM2cOs2fP5uGHH+Zvf/sbCxYsICAgoMZqrE7qma1JhnHyQbDV/z7tQbAUPQgmIiK1j2FYf9Vvx3aR42VjY2NJSEhgz549tGrVymNr0aKF+7rIyEhuv/12PvjgA7744gu++uorjh8/DkBAQABOp7PSNURGRpKQkMCSJUs8zi9ZsoQOHTqcVw0hISEMGzaMN998k/nz57Ns2TI2btxY6Zq8jXpma1qXW2H2M5C+GQ6t4YYuXXnh280cOJHP4l1HGaCxsyIiIl7jj3/8I4888ghRUVEMGTKEwsJCVq1axYkTJ3jsscd49dVXiY+Pp1u3bjgcDqZMmUJcXBzR0dGANaPB3Llz6devH0FBQdSrV++sn5WcnMy6des8zrVu3Zonn3yS5557jksuuYSuXbvy8ccfs27dOj777DOACmuYNGkSTqeT3r17ExoayqeffkpISIjHuFpfpzBb00LqQYfhsOELWP1vgm/s4X4Q7PPlKQqzIiIiXuS+++4jNDSUv/3tbzz55JOEhYXRuXNnxo8fD0BERAR//etf2blzJ35+fvTs2ZPvv/8eh8P6y+9XXnmFxx57jA8++IDGjRuzd+/es37WY489dsa5RYsW8cgjj5CZmcnjjz9Oeno6HTp0YPr06bRu3fqcNURHR/Pyyy/z2GOP4XQ66dy5M99++y0NGjSo8j8ruximadapv9vOysoiKiqKzMxMIiMj7Sli72KYdD0EhsPj29l2wsWQ1xfh7zBY+vTVxEQG21OXiIjIRSooKCA5OZkWLVoQHKz/PZOzq+iflQvJaxoza4dm/aB+SyjKgc1TaRcXSfem0ZS4TKasPmB3dSIiIiI+Q2HWDqc+CLbmEwD3g2CTV+pBMBEREZHzpTBrl6RfgMMfDqyA9K3c0CWBiGB/9h/PZ8nuo3ZXJyIiIuITFGbtEhELbYZYx2s+ISTQj5u6NQbg8+UpNhYmIiIi4jsUZu1UtiLY+v9CSSF39i5dEWzLYdKztSKYiIiIyLkozNqp1UCIbAz5J2DbDNrFRdKt9EGwL/UgmIiI+LA6NlmSVEJV/TOiMGsnhx90u8s6Xv1v4JQHwVbs14NgIiLic8qWeS0qKrK5EvF2Zf+MlP0zU1laNMFuXUfBgr9C8gI4nsywLk15ccYWUo7nsWT3Ufq31iIKIiLiO/z9/QkNDeXIkSMEBAS4Fw8QOZXL5eLIkSOEhobi739xcVRh1m71msElV8Hun2Dtp4QMfIaR3RrzybJ9/HdFisKsiIj4FMMwiI+PJzk5mX379tldjngxh8NB06ZNMQzjou6jMOsNuo+2wuy6z+DKCdzRsymfLNvHj5sPcyS7kEYRQXZXKCIict4CAwNp3bq1hhpIhQIDA6uk515h1hu0vR5CG0B2KuyaTYe2Q0lKjGb9/gy+WXeQ+/q3tLtCERGRC+JwOLScrdQIDWTxBv6BkHSndVy6Itgt3a05Z79ec9CuqkRERES8nsKstyhb3nbHLMhK5YYuCQT4GWxJzWJbWpa9tYmIiIh4KYVZb9GoLSReBqYT1n9OvbBArm4XA8BU9c6KiIiIlEth1pv0KF0RbM1/wOViZLcmAExdexCn5pwVEREROYPCrDfpMByCIuFEMuxdxFXtGhEdGkB6diFLdh21uzoRERERr6Mw600Cw6DzLdbxmk8I8vdjWJcEwOqdFRERERFPCrPepuxBsK3TIe84I0tnNfhhUxq5hSU2FiYiIiLifRRmvU1CN4jrDM4i2Pw13RKjadEwjPxiJz9sSrO7OhERERGvojDrjbrcYe3Xf4FhGIzsVjrn7NoDNhYlIiIi4n0UZr1R51vAcMCBFXBstzvMLt19jNTMfJuLExEREfEeCrPeKCIOWl5lHW+cQmL9UHq1qI9pwrS1h+ytTURERMSLKMx6qy63W/v1k8E0GdHV6p2dsUFhVkRERKSMwqy3an8DBIRZc84eWMmQTnH4Oww2H8piz5Ecu6sTERER8QoKs94qMAzaD7OO10+mflgg/Vo1BGDGhlQbCxMRERHxHgqz3iypdKjB5q+hpIhhSdYCCt+u11ADEREREVCY9W4troDwOMg/Abtmc23HWAL9HOxMz2F7Wrbd1YmIiIjYTmHWmzn8Ti5vu34ykcEBXNG2EaDeWRERERFQmPV+SaULKOz4AfIz3EMNZmw4hGmaNhYmIiIiYj+FWW8X1xliOlrL226ZxsB2MQQHONh7LI9NB7Psrk5ERETEVgqzvqBsqMGmrwkL8mdg+1gAvtWcsyIiIlLHKcz6go4jrf3eRZCTzg2d4wGYuSlVQw1ERESkTlOY9QX1W0BCdzBdsHU6V7RtRJC/g/3H89maqlkNREREpO5SmPUVnW6y9pumEhroz4A21qwGszan2ViUiIiIiL0UZn1F2VCDfUsgK5XBHeMAhVkRERGp2xRmfUVUE0jsDZiw5RsGtY/Bz2GwLS2bfcdy7a5ORERExBYKs76krHd281SiQwO5rGV9QL2zIiIiUnfZGmbfeecdunTpQmRkJJGRkfTp04eZM2ee9fpJkyZhGIbHFhwcXIMV26zDCMCA/T9D5oFThhoctrUsEREREbvYGmabNGnCyy+/zOrVq1m1ahVXX301w4cPZ/PmzWd9T2RkJKmpqe5t3759NVixzSLjoVlf63jzNK7tYIXZNSknSM8usLEwEREREXvYGmaHDRvGddddR+vWrWnTpg1/+tOfCA8P5+effz7rewzDIC4uzr3FxsbWYMVeoGyowdbpxEUFk5QYjWnC7C3qnRUREZG6x2vGzDqdTiZPnkxubi59+vQ563U5OTk0a9aMxMTEc/biAhQWFpKVleWx+bR211v7/cshO43BHa0w/8MmjZsVERGRusf2MLtx40bCw8MJCgriwQcfZOrUqXTo0KHca9u2bctHH33EN998w6efforL5aJv374cOHDgrPefOHEiUVFR7i0xMbG6vkrNiEyAxpdax9u+Y0jpuNllu4+RmV9sY2EiIiIiNc8wbV4PtaioiJSUFDIzM/nyyy/58MMPWbBgwVkD7amKi4tp3749d955Jy+++GK51xQWFlJYWOh+nZWVRWJiIpmZmURGRlbZ96hRi1+DOc/DJVfDL6dyzasL2Jmew+u3d2VEt8Z2VyciIiJyUbKysoiKijqvvGZ7z2xgYCCtWrWiR48eTJw4kaSkJN54443zem9AQADdunVj165dZ70mKCjIPVtC2ebz2g2z9skLIT9DCyiIiIhInWV7mD2dy+Xy6EmtiNPpZOPGjcTHx1dzVV6mYSto1B5cJbBjljvMLthxhMISp83FiYiIiNQcW8PshAkTWLhwIXv37mXjxo1MmDCB+fPnM2rUKABGjx7NhAkT3Ne/8MIL/Pjjj+zZs4c1a9Zw1113sW/fPu677z67voJ92t9g7bd9S6fGkcREBJFX5GT5nuP21iUiIiJSg2wNs+np6YwePZq2bdsycOBAVq5cyaxZs7jmmmsASElJITU11X39iRMnuP/++2nfvj3XXXcdWVlZLF269LzG19Y67UrD7K65GCUFXNU2BoCftqXbWJSIiIhIzbL9AbCadiEDir2aacLrXSAzBe74nB9KevDgp6tp3iCU+U9eZXd1IiIiIpXmUw+ASSUZxsk5Z7d+y+WtGxLgZ7D3WB57juTYW5uIiIhIDVGY9WVl42Z3zCI8wKBXi/qAhhqIiIhI3aEw68sSL4PgKMg/DgdWucfNzt9+xObCRERERGqGwqwv8/OHVoOs4x0/cHU7K8wuTz5GTmGJjYWJiIiI1AyFWV/XZoi13zGLFg3DaNYglGKnyeKdR+2tS0RERKQGKMz6ulaDwHBA+maMzAPuoQbzNG5WRERE6gCFWV8XWh+a9LKOd85yDzWYtz2dOjbrmoiIiNRBCrO1QZvB1n7HLHq1qE9IgB/p2YVsPpRlb10iIiIi1UxhtjYoGzebvJBgs5B+rRoCGmogIiIitZ/CbG0Q0x6iEqGkAJIXclW7RoA11EBERESkNlOYrQ0M45ShBj+4HwJbuz+D47lFNhYmIiIiUr0UZmuLsqEGO38kISqYdnERmCYs3qUpukRERKT2UpitLZpfDv7BkHUQjmzj8tJxs4t3ajUwERERqb0UZmuLgBBo1s863jWX/m2scbOLdh7VFF0iIiJSaynM1iatBlr73XPp1bw+gX4OUjML2H0k1966RERERKqJwmxtcsnV1n7fUkKMInq2qAfAIg01EBERkVpKYbY2adQOIhKsKbr2LaF/a2uoweKdeghMREREaieF2drEMKBVae/srp/cD4Et23OMohKXjYWJiIiIVA+F2drmkpPjZjvER9IgLJC8IidrU07YW5eIiIhINVCYrW1aXgmGA45sw5F90L207SINNRAREZFaSGG2tgmtDwndrePdP9G/dWmY1eIJIiIiUgspzNZGZbMa7P7J/RDYhgMZZORpaVsRERGpXRRmayP3fLPziIsIoHVMOKYJS3cfs7cuERERkSqmMFsbNb4UgqKgIAMOrePysqEGmm9WREREahmF2drIzx+aX24dJy9gQOlQg4U7tLStiIiI1C4Ks7VViwHWPnkhvVvWJ8DP4GBGPnuP5dlbl4iIiEgVUpitrcrCbMrPhDqc9GhmLW27WEMNREREpBZRmK2tYtpDWCMoyYcDK92rgekhMBEREalNFGZrK8PwGGrQ55KTS9u6XBo3KyIiIrWDwmxtdkqY7dIkirBAPzLyitmSmmVvXSIiIiJVRGG2NmtxhbU/sJIAZz69WtQHYJmGGoiIiEgtoTBbm9VrDlFNwVUC+5bRzz1uVkvbioiISO2gMFubeYybXUCfSxoAsCL5OMVOl42FiYiIiFQNhdna7pRxs+3jIokODSC3yMmGAxm2liUiIiJSFRRma7uyMJu6HkdhBn1aWr2zS3dp3KyIiIj4PoXZ2i4yHhq2AUzYu5i+mm9WREREahGF2brglKEGfUvHza5OOUFBsdPGokREREQunsJsXVA2RVfyQlo2DCM2MoiiEher952wty4RERGRi6QwWxc0vxww4Mg2jJx0+l2iKbpERESkdlCYrQtC60NcZ+s4eaF7ii6NmxURERFfpzBbV5SNm927yB1mNxzIJLug2MaiRERERC6Owmxd0by/td+7mCb1QmnWIBSny2RF8nF76xIRERG5CAqzdUXTy8BwwPHdkHWIvpdoii4RERHxfQqzdUVINMR1sY73LnZP0aUwKyIiIr5MYbYuaVE21GARl5WuBLY1NYvjuUU2FiUiIiJSeQqzdckp42YbRQTRNjYCgGXqnRUREREfpTBbl7jHze6BzIP0bVU21EDzzYqIiIhvUpitS4KjID7JOt63xP0QmHpmRURExFcpzNY1zS+39skL6dWiPg4D9hzNJTUz3966RERERCpBYbauaV62eMJiokIC6NwkGoClu9Q7KyIiIr5HYbauKRs3eyIZMg+4p+haonGzIiIi4oMUZuua4EiI72od713iDrPLdh/DNE376hIRERGpBIXZuqhs3OzeRfRsXp9AfwepmQXsOZprb10iIiIiF0hhti5qfnLxhOAAP3o0rQfAkl0aaiAiIiK+RWG2Lmp6GRh+cGIvZOzn8tbWFF0KsyIiIuJrbA2z77zzDl26dCEyMpLIyEj69OnDzJkzK3zPlClTaNeuHcHBwXTu3Jnvv/++hqqtRYIjIaGrdbxvCf1aWWF26e5jOF0aNysiIiK+w9Yw26RJE15++WVWr17NqlWruPrqqxk+fDibN28u9/qlS5dy5513cu+997J27VpGjBjBiBEj2LRpUw1XXgucMm62c+MoIoL9yS4oYePBTHvrEhEREbkAhullj7DXr1+fv/3tb9x7771ntN1+++3k5uYyY8YM97nLLruMrl278u67757X/bOysoiKiiIzM5PIyMgqq9vn7JwNn90C9ZrDo+t54JNV/LjlME8ObsvYq1rZXZ2IiIjUYReS17xmzKzT6WTy5Mnk5ubSp0+fcq9ZtmwZgwYN8jg3ePBgli1bdtb7FhYWkpWV5bEJGjcrIiIitYLtYXbjxo2Eh4cTFBTEgw8+yNSpU+nQoUO516alpREbG+txLjY2lrS0tLPef+LEiURFRbm3xMTEKq3fZwVFQEI363jvYvpeYoXZVftOUFDstLEwERERkfNne5ht27Yt69atY/ny5Tz00EOMGTOGLVu2VNn9J0yYQGZmpnvbv39/ld3b57nHzS7mkkZhxEUGU1TiYtXeE/bWJSIiInKebA+zgYGBtGrVih49ejBx4kSSkpJ44403yr02Li6Ow4cPe5w7fPgwcXFxZ71/UFCQe7aEsk1KnTLfrGEY7lkNFmuogYiIiPgI28Ps6VwuF4WFheW29enTh7lz53qcmz179lnH2Mo5NO1tjZvN2AcZKfRrZS1tq3GzIiIi4iv87fzwCRMmMHToUJo2bUp2djaff/458+fPZ9asWQCMHj2axo0bM3HiRAAeffRRrrjiCl555RWuv/56Jk+ezKpVq3j//fft/Bq+q2zc7MFVsHcx/VrdBMCmQ5lk5BURHRpoc4EiIiIiFbO1ZzY9PZ3Ro0fTtm1bBg4cyMqVK5k1axbXXHMNACkpKaSmprqv79u3L59//jnvv/8+SUlJfPnll0ybNo1OnTrZ9RV8X4uyoQaLiY0MplVMOKYJy3Yfs7cuERERkfPgdfPMVjfNM3uaXXPg05shuimM38jz0zczaeleRvVuyp9Gdra7OhEREamDfHKeWbFJYul8sxkpcGKfx9K2IiIiIt5OYbauCwqHxt2t431L6N2yPg4Dko/mcuBEnr21iYiIiJyDwqycnG82eRGRwQEkJUYDsHSXemdFRETEuynMyinzzS4G4PLSoQZLdmuKLhEREfFuCrMCib3B4Q+Z1rjZsqVtl+w6Sh17PlBERER8jMKsWONmE0rHze5dTPdm0YQE+HE0p4itqdn21iYiIiJSAYVZsZSNm927mCB/P/pcYq0GtmDHERuLEhEREamYwqxYTgmzAFe2bQTAgh3pdlUkIiIick4Ks2Jpetkp42b3ckUbK8yu2nuC7IJim4sTERERKZ/CrFgCw6BxD+t472KaNQijeYNQSlymFlAQERERr6UwKyedNtSgrHdW42ZFRETEWynMykmnhlnT5IqycbPbj2iKLhEREfFKCrNyUmJvcARA5n7I2MdlLRsQ6O/gYEY+u4/k2l2diIiIyBkUZuWkU8fNJi8iNNCf3i3qAxpqICIiIt5JYVY8nWXc7PztmqJLREREvI/CrHg6fdxsaZhdnnyc/CKnjYWJiIiInElhVjyVjZvNOgAn9tIqJpzG0SEUlbhYuvuo3dWJiIiIeFCYFU+BodDkUut472IMw+DqdjEAzNmqoQYiIiLiXRRm5UzuoQaLABjUIRaAuVsP43Jpii4RERHxHgqzcqbTxs1e1rI+YYF+pGcXsvFgpr21iYiIiJxCYVbO1KRX6bjZg3AimSB/P/cCCnO2Hra5OBEREZGTFGblTKeNmwUY1N4aajB7i8KsiIiIeA+FWSlf8/7WvjTMXtU2BocB29KyOXAiz8bCRERERE5SmJXylY2bTV4Epkm9sEAubWatBjZXsxqIiIiIl1CYlfI16Ql+gZB9CI7vAWBQh7IpujTUQERERLyDwqyULzAUGpc/bvbnPcfIKii2qzIRERERN4VZObtTp+gCWjYKp2WjMIqdJgu2H7GxMBERERGLwqycXYtTHgIzrcUSru0QB8APm9LsqkpERETETWFWzu7UcbPHdgNwXWcrzP60LZ38Iqed1YmIiIgozEoFAkKg6WXW8a45AHRuHEWTeiHkFztZsEOzGoiIiIi9FGalYq2usfa7ZgNgGAbXdY4H4LuNGmogIiIi9lKYlYq1Lg2zexdDkbVYwtBOpUMNth6moFhDDURERMQ+CrNSsUbtILIJlBS4ZzXomhhNQlQwuUVOFu7QrAYiIiJiH4VZqZhhnOydPWWowdDSoQYzNauBiIiI2EhhVs6tLMzunO0+VTarwZwthyks0VADERERsYfCrJxbiwHgCIATye4purol1iM2MojswhIW7zxqc4EiIiJSVynMyrkFRUCzPtZxae+sw2EwtJM11GDGhlS7KhMREZE6TmFWzs9pU3QB3Ng1AYBZm9PIKyqxoyoRERGp4xRm5fycOkVXcT4A3RKjadYglLwiJz9uPmxjcSIiIlJXKczK+WnUDqISrSm6khcB1qwGI7o2BuDrtQftrE5ERETqKIVZOT+nTtG14wf36ZHdrDC7eOcR0rML7KhMRERE6jCFWTl/ba+z9jt+ANMEoHnDMLo1jcZlwrfr9SCYiIiI1CyFWTl/zftDQBhkHYS0De7TZb2zU9cesKsyERERqaMUZuX8BQTDJVdZx9tnuk/f0CUBf4fBpoNZ7DycbVNxIiIiUhcpzMqFaTvU2p8SZuuHBXJl20YATNWDYCIiIlKDFGblwrQeDBiQug6yDrlPj3APNTiI02XaU5uIiIjUOQqzcmHCG0GTntbxKb2z13SIJTo0gNTMAhbuPGJTcSIiIlLXKMzKhWt3vbXfOt19Ksjfz/0g2Bcr9ttRlYiIiNRBCrNy4ToMt/bJiyD3mPv07T0TAZiz9TBHsgvtqExERETqGIVZuXD1W0B8EphO2DbDfbpdXCRJidGUuEy+XqNpukRERKT6KcxK5XQYYe23TPM4fUdp7+wXq/ZjmnoQTERERKqXwqxUTtlQgz0LIO+4+/SwpARCA/3YcySXVftO2FSciIiI1BUKs1I5DS6BuM6lQw2+c58OD/Lnhi7xAEzWg2AiIiJSzRRmpfLKeme3fONxuuxBsO82HiIzr7imqxIREZE6RGFWKq/DSGu/Zz7knxxS0L1pPdrFRVBQ7GLKavXOioiISPWxNcxOnDiRnj17EhERQUxMDCNGjGD79u0VvmfSpEkYhuGxBQcH11DF4qFhK4jpCK5ijwUUDMNgdJ/mAPzn5324tCKYiIiIVBNbw+yCBQsYO3YsP//8M7Nnz6a4uJhrr72W3NzcCt8XGRlJamqqe9u3b18NVSxn6DjC2m/6yuP0iG4JRAT7s+9YHgu0IpiIiIhUE387P/yHH37weD1p0iRiYmJYvXo1AwYMOOv7DMMgLi6uusuT89HpZpj3J9j9E2QfhohYAEID/bnt0kT+tTiZT5bu5aq2MTYXKiIiIrWRV42ZzczMBKB+/foVXpeTk0OzZs1ITExk+PDhbN68+azXFhYWkpWV5bFJFWpwCTTpCaYLNn3p0XTXZc0AmL/jCPuOVdzbLiIiIlIZXhNmXS4X48ePp1+/fnTq1Oms17Vt25aPPvqIb775hk8//RSXy0Xfvn05cKD8FacmTpxIVFSUe0tMTKyur1B3dbnd2q+f7HG6RcMwrmjTCNOET3/WUBARERGpeoZZiWWa9u/fj2EYNGnSBIAVK1bw+eef06FDBx544IFKFfLQQw8xc+ZMFi9e7L7v+SguLqZ9+/bceeedvPjii2e0FxYWUlhY6H6dlZVFYmIimZmZREZGVqpWOU3ecfh7G+tBsId/hpj27qafth3mV5NWERnsz/LfDyIk0M/GQkVERMQXZGVlERUVdV55rVI9s7/4xS+YN28eAGlpaVxzzTWsWLGCP/zhD7zwwgsXfL9x48YxY8YM5s2bd0FBFiAgIIBu3bqxa9euctuDgoKIjIz02KSKhdaH1tdax6f1zl7RJoam9UPJKihh+vqDNhQnIiIitVmlwuymTZvo1asXAP/73//o1KkTS5cu5bPPPmPSpEnnfR/TNBk3bhxTp07lp59+okWLFhdci9PpZOPGjcTHx1/we6UKJZUONdg4BVxO92k/h8FdlzUF4N9L91GJvwgQEREROatKhdni4mKCgoIAmDNnDjfeeCMA7dq1IzU19bzvM3bsWD799FM+//xzIiIiSEtLIy0tjfz8fPc1o0ePZsKECe7XL7zwAj/++CN79uxhzZo13HXXXezbt4/77ruvMl9FqkqbIRAcBVkHYe8ij6bbLk0kyN/BltQsVu49cZYbiIiIiFy4SoXZjh078u6777Jo0SJmz57NkCFDADh06BANGjQ47/u88847ZGZmcuWVVxIfH+/evvjiC/c1KSkpHgH5xIkT3H///bRv357rrruOrKwsli5dSocOHSrzVaSq+AdBx9IVwdZ/4dEUHRrITd2t4SMfLtpT05WJiIhILVapB8Dmz5/PyJEjycrKYsyYMXz00UcA/P73v2fbtm18/fXXVV5oVbmQAcVygVJ+ho8GQ0AoPL4dgk/++e5Kz2HQqwswDPjp8Stp0TDMxkJFRETEm1X7A2BXXnklR48e5ejRo+4gC/DAAw/w7rvvVuaWUhsk9oaGbaA474w5Z1vFhHN1uxhMEz5ekmxTgSIiIlLbVCrM5ufnU1hYSL169QDYt28fr7/+Otu3bycmRis91VmGAd1HW8drPjmj+b7LrQf8pqw6QEZeUU1WJiIiIrVUpcLs8OHD+eQTK6xkZGTQu3dvXnnlFUaMGME777xTpQWKj0m6ExwBcGgtpG7waOpzSQM6xEeSX+zks+UpNhUoIiIitUmlwuyaNWvo378/AF9++SWxsbHs27ePTz75hDfffLNKCxQfE9YQ2t9gHa/5t0eTYRjc19/qnf330r0UlbhqujoRERGpZSoVZvPy8oiIiADgxx9/5KabbsLhcHDZZZexb5+WLa3zuo+x9humQFGeR9MNXRKIjQwiPbuQb9cfsqE4ERERqU0qFWZbtWrFtGnT2L9/P7NmzeLaa63Vn9LT0zVDgECLKyC6GRRmwpZpHk2B/g7G9G0OwAeL9mgRBREREbkolQqzzz77LE888QTNmzenV69e9OnTB7B6abt161alBYoPcjig+y+t49X/PqN5VK9mhAT4sS0tm6W7j9VwcSIiIlKbVCrM3nLLLaSkpLBq1SpmzZrlPj9w4EBee+21KitOfFjXu8Dwg/0/Q9omj6ao0ABuu9RaROEDLaIgIiIiF6FSYRYgLi6Obt26cejQIQ4cOABAr169aNeuXZUVJz4sMh7aD7OOV7x3RvOvLm+BYcD87UfYeTi7hosTERGR2qJSYdblcvHCCy8QFRVFs2bNaNasGdHR0bz44ou4XHpCXUr1esDab5gCecc9mpo1COPaDrGAemdFRESk8ioVZv/whz/w1ltv8fLLL7N27VrWrl3Ln//8Z/7xj3/wzDPPVHWN4qua9YXYTlCSD2s/PaP5gQGXADB17UHSMgtqujoRERGpBSoVZv/973/z4Ycf8tBDD9GlSxe6dOnCww8/zAcffMCkSZOquETxWYZxsnd25Qfgcno092hWj17N61PsNPlIS9yKiIhIJVQqzB4/frzcsbHt2rXj+PHj5bxD6qzOt0JwNGSkwI5ZZzQ/eGVLAD5fnkJmfnENFyciIiK+rlJhNikpibfeeuuM82+99RZdunS56KKkFgkMhe6jreNyHgS7qm0MbWMjyCks4bPlWnBDRERELox/Zd7017/+leuvv545c+a455hdtmwZ+/fv5/vvv6/SAqUW6HkfLHsL9syH9K0Q097dZBgGv76iJY/9bz0fLd7Lr/q1IDjAz75aRURExKdUqmf2iiuuYMeOHYwcOZKMjAwyMjK46aab2Lx5M//5z3+qukbxdfWaQdvrrONlZ/boD0tKICEqmKM5hXy95mANFyciIiK+zDCrcD3R9evX0717d5xO57kvtklWVhZRUVFkZmZq6d2alLIcProW/AJh/EaIiPNo/tfiZF6csYXmDUKZ+/iV+DkMmwoVERERu11IXqv0ogkiF6Rpb2jSC5xFsOL9M5rv6JlIVEgAe4/l8ePmNBsKFBEREV+kMCs1p98j1n7lv6Awx6MpLMifMX2aAfDugt1U4V8YiIiISC2mMCs1p+11UL8lFGTAus/OaB7dtzlB/g7WH8hk2Z5jNV+fiIiI+JwLms3gpptuqrA9IyPjYmqR2s7hB33GwnePw7K34dJ7we/kP4INw4O47dJE/vPzPt5dsIe+lzS0sVgRERHxBRfUMxsVFVXh1qxZM0aPHl1dtUptkPQLCG0AGftg27dnNN/fvyUOAxbuOMLmQ5k2FCgiIiK+5IJ6Zj/++OPqqkPqisBQ6Hk/LHgZlrwJHUZYy96WatoglOu7JPDt+kO8v3APb9zRzb5aRURExOtpzKzUvJ73gX8wHFoD+5ae0fzrAdYStzM2pLL/eF5NVyciIiI+RGFWal54I+j6C+t48WtnNHdqHEX/1g1xukw+XLSnhosTERERX6IwK/bo+wgYDtg1G1LXn9H84BWXAPDFqv0cyyms6epERETERyjMij3qt4BOt1jHi145o7nvJQ3o3DiKgmIX/162r4aLExEREV+hMCv2ufy31n7LdDiyw6PJMAx37+wny/aSV1RS09WJiIiID1CYFfvEdoC21wMmLHn9jOYhneJo1iCUjLxivli5v8bLExEREe+nMCv26v+Ytd/wBWSkeDT5OQzu72/NbPDhomSKna6ark5ERES8nMKs2KvJpdDiCnCVwNJ/nNF8S48mNAwP4mBGPtPXHbKhQBEREfFmCrNiv/6PW/s1n0BOukdTcIAfv7q8OQDvLNiNy2XWcHEiIiLizRRmxX4tBkDjS6GkAJa9fUbzXZc1IyLIn13pOczeetiGAkVERMRbKcyK/QwDBjxhHa/8EPKOezRHBgfwyz7NAPjn/N2YpnpnRURExKIwK96hzRCI6wxFOeX2zv7q8hYE+TtYvz+DZbuP2VCgiIiIeCOFWfEOhgFXPGUdL3/vjN7ZhuFB3N4zEbB6Z0VERERAYVa8SdvrIbYTFGXD8nfPaL6/f0v8HAaLdx1lw4GMmq9PREREvI7CrHgPhwMGPGkd//wu5Gd4NCfWD2V4UgIA/5yn3lkRERFRmBVv0/5GiOkAhZnWcIPTPHiltcTtrC1p7ErPqenqRERExMsozIp38eidfRsKMj2a28RGcE2HWEwT3l2g3lkREZG6TmFWvE+H4dCwrRVkl79/RvPDpb2z09Ye5GBGfk1XJyIiIl5EYVa8j8MPrviddbzsLSjM9mju1rQefVo2oMRl8sHCPTYUKCIiIt5CYVa8U8eR0KA1FGTAinJ6Z6+yemcnr0zhWE5hDRcnIiIi3kJhVryTw+/k2Nmlb0Gh58Nel7dqSOfGURQUu5i0dG/N1yciIiJeQWFWvFenm6F+S8g/bi1zewrDMNxjZ/+9dC/ZBcV2VCgiIiI2U5gV7+Xnf0rv7D/O6J0d3DGOlo3CyCoo4dOfU2woUEREROymMCverfNtUK8F5B09Y+ysw2Ew9spWAHy4aA95RSV2VCgiIiI2UpgV7+bnD1dOsI6XvHHGvLPDuybQtH4ox3KL+Hy5emdFRETqGoVZ8X6dbymddzYDlv3To8nfz8G4q6ze2XcX7KGg2GlDgSIiImIXhVnxfg4/uOr31vHP/4S84x7NI7s3pnF0CEdzCvnvCvXOioiI1CUKs+Ib2t8IsZ2hMAuWvunRFODnYKy7d3a3emdFRETqEIVZ8Q0OB1z9B+t4+XuQk+7RfHOPxiREBXM4q5Apq/bbUKCIiIjYQWFWfEebIdC4BxTnweLXPZqC/P14qHTe2X/O301hiXpnRURE6gKFWfEdhgFXlfbOrvwQsg55NN96aSKxkUGkZhbw1eqDNhQoIiIiNU1hVnzLJVdD077gLISFf/doCg7w48ErrN7Zt+ftotjpsqNCERERqUG2htmJEyfSs2dPIiIiiImJYcSIEWzfvv2c75syZQrt2rUjODiYzp078/3339dAteIVDAOu/j/reM0ncGKfR/OdvZrSMDyIgxn5TF2j3lkREZHaztYwu2DBAsaOHcvPP//M7NmzKS4u5tprryU3N/es71m6dCl33nkn9957L2vXrmXEiBGMGDGCTZs21WDlYqvm/aDlVeAqhoV/9WiyemdbAvDWvF2UqHdWRESkVjNM0zTtLqLMkSNHiImJYcGCBQwYMKDca26//XZyc3OZMWOG+9xll11G165deffdd8/5GVlZWURFRZGZmUlkZGSV1S417MAq+HAgGH4wdgU0bOVuyisqof9f5nEst4hXbk3i5h5NbCxURERELtSF5DWvGjObmWktVVq/fv2zXrNs2TIGDRrkcW7w4MEsW7asWmsTL9PkUmt2A9MJC172aAoN9Of+AVbv7D9+2qmxsyIiIrWY14RZl8vF+PHj6devH506dTrrdWlpacTGxnqci42NJS0trdzrCwsLycrK8tiklihbFWzjl5C+1aPpl5c1o2F4IHuP5fHV6gM2FCciIiI1wWvC7NixY9m0aROTJ0+u0vtOnDiRqKgo95aYmFil9xcbxSdBh+GACfP+7NEUFuTPw1daQw/emLtTq4KJiIjUUl4RZseNG8eMGTOYN28eTZpUPL4xLi6Ow4cPe5w7fPgwcXFx5V4/YcIEMjMz3dv+/Vodqla5cgJgwNbpkLreo+kXvZuSEBVMamYBny1Psac+ERERqVa2hlnTNBk3bhxTp07lp59+okWLFud8T58+fZg7d67HudmzZ9OnT59yrw8KCiIyMtJjk1okpj10vtU6Pq13NjjAj0cGtgbgn/N2kVtYUtPViYiISDWzNcyOHTuWTz/9lM8//5yIiAjS0tJIS0sjPz/ffc3o0aOZMGGC+/Wjjz7KDz/8wCuvvMK2bdt4/vnnWbVqFePGjbPjK4g3uPJpa1aDHT/A/pUeTTf3aEKLhmEcyy3i4yXJNhUoIiIi1cXWMPvOO++QmZnJlVdeSXx8vHv74osv3NekpKSQmprqft23b18+//xz3n//fZKSkvjyyy+ZNm1ahQ+NSS3X4BLoeqd1PPePcMpscwF+Dn57TRsA3lu4h8y8YjsqFBERkWriVfPM1gTNM1tLZeyHf/Swlrn9xRRoc627yeUyue7NRWxLy+bhKy/hd0Pa2VioiIiInIvPzjMrUmnRidD719bxnOfAdXL2AofD4Ilr2wLw8ZK9pGcX2FGhiIiIVAOFWak9+j8GwdGQvgXWe07xNrB9DF0To8kvdvLPebvtqU9ERESqnMKs1B4h9aD/49bxvD9B8ckHCQ3D4HeDrd7Zz5bvY//xPDsqFBERkSqmMCu1S68HILIJZB2E5e95NPVt1ZD+rRtS7DT526ztNhUoIiIiVUlhVmqXgGC4+g/W8eJXIe+4R/NTQ9phGDB9/SE2HMio+fpERESkSinMSu3T5XaI6QgFmbDoFY+mTo2jGNm1MQB//n4rdWwyDxERkVpHYVZqH4cfXPNH63jF+5DhuZTt44PbEujv4Oc9x5m3Pd2GAkVERKSqKMxK7dRqEDTvD86iM5a5bRwdwj39mgMw8fttlDhdNhQoIiIiVUFhVmonwzjZO7t+MqRt9Gh++MpWRIcGsDM9hy9XH7ChQBEREakKCrNSezXuAR1HAibMfs6jKSokgN9c3RqAV2fvIK+oxIYCRURE5GIpzErtdvUz4AiA3XNh52yPprsua0pi/RDSswt5d8EemwoUERGRi6EwK7Vbg0tOLnM76w/gLHY3Bfn7MWFoewDeW7Cbgxn55d1BREREvJjCrNR+A56E0AZwdDus+tijaWinOHq1qE9hiYuJ32+1qUARERGpLIVZqf1CouGq0oUU5v/ZYyEFwzB49oYOGAbM2JDKyr3Hy7+HiIiIeCWFWakbuo+BmA6QfwIW/NWjqVPjKG6/NBGAF77dgsulhRRERER8hcKs1A1+/jD4T9bxyg/gyA6P5sevbUtEkD8bD2by5RpN1SUiIuIrFGal7rjkamgzFFwl8OP/eTQ1igjiNwNbAfC3WdvJKdRUXSIiIr5AYVbqlmtfAoc/7JwFu+Z4NN3dtwXNG4RyJLuQt+ftsqlAERERuRAKs1K3NGwFvR6wjmf9AZwne2AD/R384foOAPxrUTIpx/LsqFBEREQugMKs1D1X/A5C6sORbbDyQ4+mQe1juLxVQ4qcLl6YscWmAkVEROR8KcxK3RNSDwY+Yx3P+xPkpLubDMPguWEd8HcYzNl6mDlbDttUpIiIiJwPhVmpm7qPgfgkKMyCOc97NLWOjeC+/i0BeP7bzeQXOW0oUERERM6HwqzUTQ4/uO4V63jdZ7B/hUfzIwNbkRAVzIET+bw1b6cNBYqIiMj5UJiVuiuxJ3S9yzr+/glwneyBDQ3057kbOwLw/sI97ErPsaNCEREROQeFWanbBj0PQVGQuh5WT/JourZDLFe3i6HYafLsN5swTa0MJiIi4m0UZqVuC28EV//BOp77AuQeczcZhsEfb+xIkL+DpbuPMX39IZuKFBERkbNRmBW59F6I7QQFGfDTCx5NifVD+c3V1spgL323layCYhsKFBERkbNRmBXx84fr/mYdr/43HFzj0Xz/gJa0bBjGkexCXv1xhw0FioiIyNkozIoANOsLnW8DzNKHwVzupiB/P14c0QmAT5btZdPBTJuKFBERkdMpzIqUueYFCAyHg6th7X88mvq1asiNSQm4TPjDtE24XHoYTERExBsozIqUiYyHKydYx7Of9VgZDOD/rm9PeJA/6/dnMHnlfhsKFBERkdMpzIqcqveDENfFehhs5lMeTTGRwTx+bRsA/vLDNo7lFNpQoIiIiJxKYVbkVH7+cOObYDhg89ewY5ZH8y8va0aH+Egy84t5eeY2m4oUERGRMgqzIqdL6AaXPWwdf/c4FJ5c/cvfz8GfRnbCMGDK6gMs3X3UpiJFREQEFGZFynfV7yG6KWTuh59e8mjq1rQeo3o3BeD3X2+koNhZ3h1ERESkBijMipQnMAxueM06Xv4uHFjt0fzUkHbERwWz91ger83R3LMiIiJ2UZgVOZtWg07OPfvtI+A8ufpXRHAAL5XOPfvhomTNPSsiImIThVmRigyZCCH14PAmWPoPj6aB7WMZlpSA02Xyuy83UOx0neUmIiIiUl0UZkUqEtYQBv/ZOl7wFzi226P5uWEdiA4NYEtqFu8v3GNDgSIiInWbwqzIuSTdCS2vhJICmDEezJOrfzUMD+LZGzoA8Mbcnew+klP+PURERKRaKMyKnIthWA+D+YdA8kJY97lH88hujRnQphFFJS4mfLVRS92KiIjUIIVZkfNRvyVc+bR1/OMfIOeIu8kwDP48shOhgX6s2Hucz1ek2FSkiIhI3aMwK3K++oyDuM6QfwJ+eNqjqUm9UH43uC0AL8/cRmpmvh0VioiI1DkKsyLny88fhpUudbvpS9g526P5l32a071pNDmFJTwzbROmqeEGIiIi1U1hVuRCNO4OvR+yjmc85rHUrZ/D4C83dyHQz8GcrelMX3/IpiJFRETqDoVZkQt11e8hqilkpsC8P3s0tY6NYNzVrQB4bvpm0rMK7KhQRESkzlCYFblQQeGnLHX7Dhz0XOr2oSsvoVPjSDLyinn6640abiAiIlKNFGZFKqP1IOh8K5gumP6ox1K3AX4OXr2tK4F+Dn7als6UVQdsLFRERKR2U5gVqazBZUvdboTFr3k0tYmN4PFr2wDwwowtHDiRZ0eFIiIitZ7CrEhlhTeCoX+1jhf8BVI3eDTf178llzarR05hCU9O2aDFFERERKqBwqzIxeh8K7S7AVwlMO0hKClyN/k5DP5+axIhAX4s23OMT5btta9OERGRWkphVuRilC11G1IfDm+ChX/zaG7eMIzfX9cOgJd/2MaeIznl3UVEREQqSWFW5GKFx8ANr1rHi16Bg2s8mkf1bsblrRpSUOzi8SnrKXG6bChSRESkdlKYFakKHUdam+m0hhsUn5xf1uEw+OstXYgI8mdtSgbvLdxjY6EiIiK1i8KsSFW57hUIawRHtsH8iR5NCdEhPHdjRwBen7ODjQcy7ahQRESk1rE1zC5cuJBhw4aRkJCAYRhMmzatwuvnz5+PYRhnbGlpaTVTsEhFwhrADa9bx0vfhP0rPZpv7t6YIR3jKHaaPDJ5LbmFJTVfo4iISC1ja5jNzc0lKSmJt99++4Let337dlJTU91bTExMNVUocoHa3wBdbrcWU5j2IBTnu5sMw+DlmzsTFxlM8tFcXvh2i42FioiI1A62htmhQ4fy0ksvMXLkyAt6X0xMDHFxce7N4dBoCfEiQ/8C4XFwbBfMfdGjKTo0kNdu74phwBer9vP9xlSbihQREakdfDIFdu3alfj4eK655hqWLFlidzkinkLqwY3/sI5//ifsW+rR3OeSBjx0xSUAPP3VBg5l5J9+BxERETlPPhVm4+Pjeffdd/nqq6/46quvSExM5Morr2TNmjVnfU9hYSFZWVkem0i1a3MtdLsLMGHqr6HA84Gv317ThqQmUWQVlPDbL9bh1OpgIiIileJTYbZt27b8+te/pkePHvTt25ePPvqIvn378tprr531PRMnTiQqKsq9JSYm1mDFUqcNngjRzSAjBb5/0qMpwM/BG3d0IyzQj+XJx3l3wW6bihQREfFtPhVmy9OrVy927dp11vYJEyaQmZnp3vbv31+D1UmdFhwJN30AhgM2fAEbv/Robt4wjD8O7wTAq7N3sHrfcTuqFBER8Wk+H2bXrVtHfHz8WduDgoKIjIz02ERqTNPeMOB31vGMx6xe2lPc3L0xNyYl4HSZjPt8Lcdzi2woUkRExHfZGmZzcnJYt24d69atAyA5OZl169aRkmL9D/6ECRMYPXq0+/rXX3+db775hl27drFp0ybGjx/PTz/9xNixY+0oX+T8DHgSmvSEwkz4+tfgcrqbDMPgzzd1pmWjMFIzCxj/xTpcGj8rIiJy3mwNs6tWraJbt25069YNgMcee4xu3brx7LPPApCamuoOtgBFRUU8/vjjdO7cmSuuuIL169czZ84cBg4caEv9IufFzx9ueh8CwyFlKSz2HOMdHuTPP0d1JzjAwcIdR/jn/LMPmxERERFPhmmadaobKCsri6ioKDIzMzXkQGrWus9h2kPg8Id7f4TGPTyap6zaz5NfbsBhwKf39abvJQ1tKlRERMReF5LXfH7MrIjPSLoTOo4EVwl8dT8U5ng033ppIrf2aILLhEf+u470rAKbChUREfEdCrMiNcUw4IbXILIxHN8NPzx9xiUvDO9Eu7gIjuYU8pv/rqXE6bKhUBEREd+hMCtSk0Lqwcj3AAPW/gc2TPFsDvTj7VHd3fPP/m3WdnvqFBER8REKsyI1rUV/a4YDgG8fhSM7PJovaRTOX27pAsB7C/fwzbqDNV2hiIiIz1CYFbHDlU9D8/5QnAtTxkBRnkfzDV0SeOjKSwB46qsNbDqYWd5dRERE6jyFWRE7OPzg5n9BWAykbzljuVuAJ65ty5VtG1FQ7OLX/1nN0ZxCGwoVERHxbgqzInaJiIVb/mUtd7vuU2vqrlP4OQzeuKMbLRuGcTAjn4c/W0OxHggTERHxoDArYqcWA+DKCdbxjMfg8BaP5qiQAN4f3YPwIH9WJB/nxRlbyrmJiIhI3aUwK2K3/o9Dy6ugJN8aP3va/LOtYiJ4/fauGAZ8smwfk1eknOVGIiIidY/CrIjdHH5w0wcQEQ9Hd8A3D8NpC/MN6hDLY4PaAPB/0zaxdNdROyoVERHxOgqzIt4gvBHc+m9wBMCWb2Dxq2dcMu7qVgzvmkCJy+TXn65m5+FsGwoVERHxLgqzIt6iaW+47q/W8dwXYeccj2bDMPjLzV3o2bwe2QUl3DNpJUeyNcOBiIjUbQqzIt7k0l9B9zGACV/9Co7t9mgODvDjvV9eSvMGoRw4kc99n6wiv8hpT60iIiJeQGFWxNtc9zdo0gsKMmHyqDMeCKsfFsjH9/QiOjSA9fszGP/FWpwu8yw3ExERqd0UZkW8jX8Q3PYJhMfCka3lPhDWomEY7//yUgL9HMzafJj/m7YJ01SgFRGRukdhVsQbRcbDbf85+UDYwr+fcUmvFvV5/Q5ryq7/rkjhlR932FCoiIiIvRRmRbxV095wfWmInfcSbPrqjEuu6xzPn0Z0BuCtebv4aHFyTVYoIiJiO4VZEW/W4264bKx1PPUhSFl+xiW/6N2UJ6615qB9YcYWpq49UIMFioiI2EthVsTbXfsitL0OnIUw+Rdw/Mze17FXteJX/VoA8OSUDfywKa2mqxQREbGFwqyIt3P4wc0fQnwS5B2Fz2+D/AyPSwzD4P+ub89N3RtT4jIZ9/kaftysQCsiIrWfwqyILwgMgzu/gMjG1pK3X9wFJZ4LJjgcBn+7Jcm9StjYz9cwe8thmwoWERGpGQqzIr4iMh5+8QUEhsPeRfD1A+DyXDDBz2Hwyq1J3JiUQLHT5OHPVjN3qwKtiIjUXgqzIr4krjPc8VnplF3TYOZTZ8xB6+/n4NXbkrihSzzFTpOHPl3DT9sUaEVEpHZSmBXxNS2vhJveAwxY+QEsOnMOWn8/B6/f3pXrO8dT5HTx4H/WMEdDDkREpBZSmBXxRZ1uhqF/sY5/eglW//uMS/z9HLx+R1eGdoqjyOni15+uZtragzVcqIiISPVSmBXxVb1/DZc/Zh3PGF/uogoBfg7evLMbN3VrjNNlMv6Ldfx76d4aLVNERKQ6KcyK+LKBz0L3MWC64Kv7Yeu3Z1wS4Ofg77cmcXff5gA8N30zb8zZiXnaWFsRERFfpDAr4ssMA254HbrcAaYTptwDO2adcZnDYfDcsA78dpC1Uthrc3bw3PTNOF0KtCIi4tsUZkV8ncMBw9+GjjeBqxi++CXsmnvGZYZh8Oig1jw/rAMAnyzbxwOfrCK3sKSmKxYREakyCrMitYGfP9z0PrS7oXTZ21HlBlqAu/u14J+juhPk72DutnRue28ZaZkFNVywiIhI1VCYFakt/ALglo+hzRAoyYf/3gFbZ5R76XWd45n8wGU0DA9k86EsRry9hM2HMmu4YBERkYunMCtSm/gHwm3/gfY3grMI/jca1n9R7qXdmtZj6sP9aBUTTlpWAbe+u4zvNqTWcMEiIiIXR2FWpLbxD7R6aLuOsh4Km/prWPmvci9NrB/KVw/15fJWDckrcjL28zX85YdtejBMRER8hsKsSG3k5w83vgW9HgBM+O4xWPJGuZdGhQQw6Z6ePDCgJQDvzN/NPZNWkpFXVIMFi4iIVI7CrEht5XDA0L9C/8et17OfhdnPgct1xqX+fg5+f1173rijK8EBDhbuOMKNby1h4wGNoxUREe+mMCtSmxmGtbDCoOet10teh6/uheLyZy8Y3rUxXz3Ulyb1Qkg5nsdN7yzhw0V7cGnYgYiIeCmFWZG64PLfwoh3wREAm7+G/4yAvOPlXtoxIYrvftOfIR3jKHaavPTdVn7175UczSms2ZpFRETOg8KsSF3R9U646ysIioKUZfDhIDi+p9xLo0IDeOeu7rw0ohOB/g7mbz/C0DcWsWTX0RouWkREpGIKsyJ1Scsr4N5ZEJUIx3fDB1fDnvnlXmoYBndd1ozp4/rROiacI9mF3PWv5bw4Ywv5Rc6arVtEROQsFGZF6pqY9nDfXEjoDvkn4D83wc/vgFn+uNh2cZFMH3c5d/ZqimnCvxYnM/j1hSzdrV5aERGxn8KsSF0UEQv3zISkO625aH94GqY9BEW55V4eEujHxJs68/E9PYmPCibleB6/+GA5f5i6keyC4houXkRE5CSFWZG6KiAYRrwDgyeC4YD1/4X3roDUDWd9y1VtY/jxtwMY1bspAJ8tT2HwawuZtz29pqoWERHxYJjmWf5usZbKysoiKiqKzMxMIiMj7S5HxDskL4Kv74fsVPALhGtfshZcMIyzvmXZ7mM89dUGUo7nATCiawK/v649MZHBNVW1iIjUUheS1xRmRcSSewy+GQs7Zlqv2wyF4W9DWIOzviWvqIRXftzBR0uSMU0IC/TjkYGtuadfCwL99Rc/IiJSOQqzFVCYFamAacKK9+HH/wNnEUTEw00fQIv+Fb5tw4EMnv1mM+v2ZwDQsmEYzw7rwJVtY2qgaBERqW0UZiugMCtyHlI3wJe/gmM7AQMGPAFXPA1+/md9i8tl8vXag7w8c5t7gYVB7WP43ZB2tImNqKHCRUSkNlCYrYDCrMh5KsqFmb+DtZ9ar+O7Wg+MxXao8G3ZBcW8OXcnHy/ZS4nLxGHAyG5NGD+oNYn1Q6u/bhER8XkKsxVQmBW5QBu/hO8eh4IMazncK5+CfuPBL6DCt+1Kz+GVH7czc1MaAAF+BqN6N2PsVa1oFBFU/XWLiIjPUpitgMKsSCVkp8G3408+HNaoPQz9i7Wi2Dms35/B32ZtZ3HpUrihgX78ql8L7u/fkqjQigOxiIjUTQqzFVCYFakk04QNX1gLLOSfsM61v9Gaxqtes3O+fcmuo/z1h22sP5AJWDMf3NWnGfdd3lI9tSIi4kFhtgIKsyIXKe84zJ8IKz8E0wX+wdawg36PQmDFY2JN02TW5sO8PmcH29KyAQjyd3B7z0QeGNCSJvU0plZERBRmK6QwK1JF0jZZvbR7F1mvoxKtXtoOwytcbAGsmQ9+2pbOW/N2uafz8ncYDEtK4O6+zUlKjK7e2kVExKspzFZAYVakCpkmbPnGmpc2c791rnl/azxtbMfzeLvJsj3H+Oe83e4xtQDdmkZzd9/mDO0Ur8UXRETqIIXZCijMilSDojxY8gYseR1KCgADutwGVz4N9Vue1y02HMhg0pK9fLvhEMVO6z9LjSKCGNW7Kb/o3ZSYCC2TKyJSVyjMVkBhVqQandgHs5+xemsBHP7Q7S4Y8DuIanxetziSXch/V6Tw6c/7SM+2Fl/wdxgMah/L7T0TGdCmEX6OiocxiIiIb1OYrYDCrEgNOLQWfnoJds2xXvsFWaG23yNQr/l53aKoxMUPm9OYtCSZNSkZ7vPxUcHc0qMJt12aqEUYRERqqQvJa7YORlu4cCHDhg0jISEBwzCYNm3aOd8zf/58unfvTlBQEK1atWLSpEnVXqeIXKCEbnDXV3DPTGjWD5yFsOpf8GZ3+PrXcGT7OW8R6O/gxqQEvn64Hz+M7889/ZoTHRpAamYB//hpF/3/Oo/b3l3Gpz/v43huUQ18KRER8Ua29szOnDmTJUuW0KNHD2666SamTp3KiBEjznp9cnIynTp14sEHH+S+++5j7ty5jB8/nu+++47Bgwef12eqZ1akhpkm7FsKi16B3XNLTxrQ/gboMw4Se59z9oMyhSVOftx8mP+t2s/iXUcp+6+Xv8NgQJtGDO+awKD2sYQF+VfPdxERkRrhk8MMDMM4Z5h96qmn+O6779i0aZP73B133EFGRgY//PDDeX2OwqyIjQ6ugcWvwtZvT56L6ww974fOt55zntpTHcrIZ8aGQ0xff4hNB7Pc50MC/LiqXSOu6RDLVW1jiA4NrMpvICIiNaDWhtkBAwbQvXt3Xn/9dfe5jz/+mPHjx5OZmVnuewoLCyksLHS/zsrKIjExUWFWxE7p22DZP2Djl6WzHwDBUdD1Luh5LzS45IJutys9h+nrDzF93UH2Hstzn/dzGPRsXo9B7WO5tkMcTRtojK2IiC+4kDDrU38Xl5aWRmxsrMe52NhYsrKyyM/PJyQk5Iz3TJw4kT/+8Y81VaKInI+YdjD8bbjmRVj3mbWa2Im98PPb1nbJQCvUtroG/M/ds9oqJpzHrmnDbwe1ZuPBTGZvOczsLYfZlpbNz3uO8/Oe47z03VbaxIZzTYdYBrWPJalJNA7NiiAi4vN8KsxWxoQJE3jsscfcr8t6ZkXEC4TWh76/gcvGWjMfrPwAds62xtbungsh9aDjTdDldkjsdc6xtYZh0KVJNF2aRPP4tW3ZfzyPOVutYLs8+Tg7Duew43AOb8/bTcPwIAa0bkj/Ng3p16qh5rEVEfFRPhVm4+LiOHz4sMe5w4cPExkZWW6vLEBQUBBBQUE1UZ6IVJbDAW2utbbje2DVR7Dhf5Bz2JoFYdW/ILqZtRBDl9uhYevzum1i/VDu6deCe/q1IDOvmPk70pm95TALth/haE4hX689yNdrDwLQLi6C/q0b0r91I3o2r09IoF91fmMREakiPjVm9qmnnuL7779n48aN7nO/+MUvOH78uB4AE6ltXE5IXmCF2q3fQlHOybaEbtD5NuhwI0Q1ueBbF5W4WLX3OIt2HWXRziMeD5ABBPhZPby9W9Snd8sG9GhWj3DNkCAiUmN85gGwnJwcdu3aBUC3bt149dVXueqqq6hfvz5NmzZlwoQJHDx4kE8++QQ4OTXX2LFj+dWvfsVPP/3EI488oqm5RGq7ojzY/r0VbHfNAdN5si0+CdpeD+2uh9iO5z3N16mO5RSyZPcxFu04wuJdR0nNLPBo93MYdEqIpHfLBvRqXp+uTaNpGK6/8RERqS4+E2bnz5/PVVdddcb5MWPGMGnSJO6++2727t3L/PnzPd7z29/+li1bttCkSROeeeYZ7r777vP+TIVZER+XcwQ2T4VNX8H+5cAp/wmLbmoF2zbXQtM+EFD+8KOKmKbJ/uP5/Jx8jOV7jrM8+RgHTuSfcV1i/RC6Jdaja2I0XZtG0zEhkiB/DU0QEakKPhNm7aAwK1KL5ByBHT/Atu9gz7yT03yBtYRu097Q8kpri+8KjsqFzYMZ+SzfY4Xb1Skn2JWec8Y1gX4O2idE0i0xmm5No+maGE3T+qEYlegpFhGp6xRmK6AwK1JLFeXC7nnWcITd8yD7kGd7cBS0GFAabq+C+i0rNSQBIDO/mA0HMliXksHa/Rms259R7pK6kcH+dEiIpEN8VOk+klYx4QT627qSuIiI11OYrYDCrEgdYJpwdCfsmW9texdBoedDXkQlQosroOll1pK6DVtXOtyWDU1Yu/8Ea1OscLvlUBZFTtcZ1wb4GbSOiaBjQqQ74LZPiCQyOKBSny0iUhspzFZAYVakDnKWQOo6ayjCngWQ8jO4ij2vCakHTXpZ89km9obG3SEwrNIfWVTiYmd6NlsOZbElNcu9zy4oKff6xPohdIiPpHVMBK1iwmkVE84ljcI1RZiI1EkKsxVQmBURinIhZRkkL4IDK+Hgas/xtgCGH8S0h7guEN/F2sd1huDK/3fDNE0OnMj3CLdbDmVxMOPMB8zKNI4OoXVsOK0ahbtDbquYcKJDz70ymoiIr1KYrYDCrIicoaQIDm+E/SusGRL2r4Csg+VfW6+FFW7jkyAuyToOj7moj8/IK2JLahZbU7PZlZ7D7vQcdh3JKXccbpmG4YFc0uhkD27zhqE0axBGk3ohmlVBRHyewmwFFGZF5LxkHoDU9ZC6AdI2WPusA+VfGx5nhdpGbaFhG2jY1hqDG1r/oko4nlvErvSck9sRK+hW1JPrMCA+KoTmDUNpWj+M5g1CadbACrrNGoQSGqjFH0TE+ynMVkBhVkQqLfcYpJ0WcI/twmOu21OFNSoNt6Vbo9KgG9nYWsK3smUUlrD7yMmQu+dILvuO57HvWC55Rc4K39sgLJDG9UJIiAqx9tEhNC7b6oVQLzRA04mJiO0UZiugMCsiVaowBw5vtoYpHNkBR0u3sw1TAAgItXpuG7aBBq2hfguo19zawhpd1KwKR3OK2Hcsl33HrHC791ieO+hm5BWf8x7BAQ7PgBttBd7YyGBiIoNoFB5EtAKviFQzhdkKKMyKSI0ozLamBzu6E45utwLukR1wfDe4yp/RALCCblmwPX2LanJRMyxk5hVzICOPQxkFHDyRx6HMAg6eyOdghrUdyS48r/sE+jloFBHk3mIigoiJOBl2YyKt1w3CAwnw05y6InLhFGYroDArIrZyFsOJvaXhdjsc2229zthnjdM925CFMkFREBkPEfEQmWDtI+JOHkcmWL27lVjtrLDESdppAfdQRj6HMgpIzy4gPbvwvHp3TxUR7E+90EDqhQYQVbqvFxpIdAX78CB/9fyK1HEKsxVQmBURr1VSaAXaE8lWwD11O74XirLP7z6GnxVwI+JLg2/CmfuIOAgKv+ASC0ucHMkuJD278OQ+ywq6J88VcDSnCKercv/zEuBnEBViBd/o0ACiQwOJCPInPNif8NJ9RHCAde6U8xGntGtGBxHfpjBbAYVZEfFJpmkNXchOhaxDp+1TreV7s1IhNx3MM1ceK1dQpBV4w2MgJBqCo8+yr3fydXAU+J17RgSnyyQjr4gTecUe+4y8Yk6U87psX1hynrWfQ6Cfg9AgP0ID/AgJ9CM00J+QQD9CAvwIDSw7Z50PDig7Lmv3JzjAQZC/H0EBDoL8S4/9HaWvS4/9HfhrGIVItbiQvKY5WkREfIFhWAs2BEdaU4CdjbPECrSnBtwz9mlWL29hlrUd3X5htQSGVxB8rb1fcDQNQqJpEBwN4dHQMBpC4sCv4mV784ucZOQXcSL3lBCcX0RuYQk5BSVkFZSQU3qcU1hCdmEJOQXF7nO5pbM5FDldFOW5yODChkVcKD+H4Q625YXfwNK2QH8HAX4OAv2sfYC/gb+j7LxhnfOr6NjzdWDp+/0cBv5+Bv4OAz+Ho3RvuPd+7tcO93mHQ0M4pHZRmBURqU38/K1xs5EJQI+zX1eYfTLg5h6F/BNQkAH5GafsMz1flw1zKMqxtrPNu1uRgDCrdzck2grFgaHWQ28BoRAQQkhgGCEBIcQHhJW2hUBwGESEeF7rHwp+gVY49gt0HzuNAHKdBjmFLnILS8grcpJX5CS/uIT8Ihd5RSXkFzvd5wuKneQVWdflFzndbYXFTgpLXNZ26nGJk2Lnyb/QdLpM972o5uBcVQyDU0Kv4yzh97R2v7OcLw3H/g4Dh2FgGFbALzt2GAaO0nNG6bF1znC3ORwnr/UrPWec1u445b2nfkbZtdZrz/ed+ZmnfLbj5LWen3nm55Vdf2rNp37mqd/Vz3Hq9z7l+3HyOoPS/SnHDsO6xii9t1wYhVkRkbooKAIaRVhz354vZ4kVcN1h98Rp4be8fab1nsJM6x7FudaWfagqv42bHxAJRDr8wS/ojLB75nHp3j8IAgMg5NzXuhyBlOBPiWlQYkKJy6DYNCgyHRS7HNbedFDkclBYtncZpddZ1xeVvqfYZVDkwto7DYpdUORyUOQ0KXIZFLig2OmgyGVS6ITC0rZCJxQ6rXsWugycpkmJy8TpOrk/25hl04Rip1kayqtmWIdULSvoegZgDGtRlNMDMGXXOsoCsRWiKQvNeAbnsms8Pquc9lPvbZwStj++pxeNo0Nq9M/jXBRmRUTk/Pj5Q1gDa7tQLudpQTgDinKhOP/kvrjsdR4Ul21naXcWWTNDOIuszTxtsQhXibVVQ2epAwgs3byK4QB/P2vv8MM0HKUpxTpnGg7AKD3vwMRwnzcxTr4uvabsnIkD07D2rrJzhgOXyRnnTr7HwKSsHcA4eZ372Go3MTBNTmnnlGuM0s8pOzZwwcnrTAPnKccurPu4TM9z1meY1j1Na84Ql0npdaa7BieAWXaPsmNKa8Bdp8vjHmXHZfc2S+9ruOcmOfPYKD22/mxOvcY87bX72DTck52cfo+zvYfT3n+2Gk5ee44aMHDmtweFWRERqXMcftbyvhe5xO9ZuZwng+2pIfdsxyVF57jm1HNnudblsh62M53W55ftXSXWda6Sk69dJVa76SrnfWXHZzl/vg/0ma6T1zo5JcpY9JfX1cCgzv3BFvr9EoixuwwPCrMiIuL7HH7gCLHG2NY2plm6lYVh52mB1/QMvu7zp2xl5zDPbDNPP3ce11R4H/OUa8xTri3v2PQ8Lre9vHtxYe8p+3P0OD5l776W83hfedeWd0wV3KOa6j9nHWd/X1BwKN5GYVZERMSblQ1qRNOAiZRH/2aIiIiIiM9SmBURERERn6UwKyIiIiI+S2FWRERERHyWwqyIiIiI+CyFWRERERHxWQqzIiIiIuKzFGZFRERExGcpzIqIiIiIz1KYFRERERGfpTArIiIiIj5LYVZEREREfJbCrIiIiIj4LIVZEREREfFZCrMiIiIi4rMUZkVERETEZynMioiIiIjPUpgVEREREZ/lb3cBNc00TQCysrJsrkREREREylOW08pyW0XqXJjNzs4GIDEx0eZKRERERKQi2dnZREVFVXiNYZ5P5K1FXC4Xhw4dIiIiAsMwqv3zsrKySExMZP/+/URGRlb750nl6HfyDfqdfIN+J9+g38k31NXfyTRNsrOzSUhIwOGoeFRsneuZdTgcNGnSpMY/NzIysk79Q+ir9Dv5Bv1OvkG/k2/Q7+Qb6uLvdK4e2TJ6AExEREREfJbCrIiIiIj4LIXZahYUFMRzzz1HUFCQ3aVIBfQ7+Qb9Tr5Bv5Nv0O/kG/Q7nVudewBMRERERGoP9cyKiIiIiM9SmBURERERn6UwKyIiIiI+S2FWRERERHyWwmw1e/vtt2nevDnBwcH07t2bFStW2F1SnbJw4UKGDRtGQkIChmEwbdo0j3bTNHn22WeJj48nJCSEQYMGsXPnTo9rjh8/zqhRo4iMjCQ6Opp7772XnJycGvwWtdvEiRPp2bMnERERxMTEMGLECLZv3+5xTUFBAWPHjqVBgwaEh4dz8803c/jwYY9rUlJSuP766wkNDSUmJoYnn3ySkpKSmvwqtdo777xDly5d3BO39+nTh5kzZ7rb9Rt5p5dffhnDMBg/frz7nH4r+z3//PMYhuGxtWvXzt2u3+jCKMxWoy+++ILHHnuM5557jjVr1pCUlMTgwYNJT0+3u7Q6Izc3l6SkJN5+++1y2//617/y5ptv8u6777J8+XLCwsIYPHgwBQUF7mtGjRrF5s2bmT17NjNmzGDhwoU88MADNfUVar0FCxYwduxYfv75Z2bPnk1xcTHXXnstubm57mt++9vf8u233zJlyhQWLFjAoUOHuOmmm9ztTqeT66+/nqKiIpYuXcq///1vJk2axLPPPmvHV6qVmjRpwssvv8zq1atZtWoVV199NcOHD2fz5s2AfiNvtHLlSt577z26dOnicV6/lXfo2LEjqamp7m3x4sXuNv1GF8iUatOrVy9z7Nix7tdOp9NMSEgwJ06caGNVdRdgTp061f3a5XKZcXFx5t/+9jf3uYyMDDMoKMj873//a5qmaW7ZssUEzJUrV7qvmTlzpmkYhnnw4MEaq70uSU9PNwFzwYIFpmlav0lAQIA5ZcoU9zVbt241AXPZsmWmaZrm999/bzocDjMtLc19zTvvvGNGRkaahYWFNfsF6pB69eqZH374oX4jL5SdnW22bt3anD17tnnFFVeYjz76qGma+vfJWzz33HNmUlJSuW36jS6cemarSVFREatXr2bQoEHucw6Hg0GDBrFs2TIbK5MyycnJpKWlefxGUVFR9O7d2/0bLVu2jOjoaC699FL3NYMGDcLhcLB8+fIar7kuyMzMBKB+/foArF69muLiYo/fqV27djRt2tTjd+rcuTOxsbHuawYPHkxWVpa751CqjtPpZPLkyeTm5tKnTx/9Rl5o7NixXH/99R6/CejfJ2+yc+dOEhISaNmyJaNGjSIlJQXQb1QZ/nYXUFsdPXoUp9Pp8Q8aQGxsLNu2bbOpKjlVWloaQLm/UVlbWloaMTExHu3+/v7Ur1/ffY1UHZfLxfjx4+nXrx+dOnUCrN8gMDCQ6Ohoj2tP/53K+x3L2qRqbNy4kT59+lBQUEB4eDhTp06lQ4cOrFu3Tr+RF5k8eTJr1qxh5cqVZ7Tp3yfv0Lt3byZNmkTbtm1JTU3lj3/8I/3792fTpk36jSpBYVZEvMbYsWPZtGmTx9gx8R5t27Zl3bp1ZGZm8uWXXzJmzBgWLFhgd1lyiv379/Poo48ye/ZsgoOD7S5HzmLo0KHu4y5dutC7d2+aNWvG//73P0JCQmyszDdpmEE1adiwIX5+fmc8fXj48GHi4uJsqkpOVfY7VPQbxcXFnfHAXklJCcePH9fvWMXGjRvHjBkzmDdvHk2aNHGfj4uLo6ioiIyMDI/rT/+dyvsdy9qkagQGBtKqVSt69OjBxIkTSUpK4o033tBv5EVWr15Neno63bt3x9/fH39/fxYsWMCbb76Jv78/sbGx+q28UHR0NG3atGHXrl3696kSFGarSWBgID169GDu3Lnucy6Xi7lz59KnTx8bK5MyLVq0IC4uzuM3ysrKYvny5e7fqE+fPmRkZLB69Wr3NT/99BMul4vevXvXeM21kWmajBs3jqlTp/LTTz/RokULj/YePXoQEBDg8Ttt376dlJQUj99p48aNHv/HY/bs2URGRtKhQ4ea+SJ1kMvlorCwUL+RFxk4cCAbN25k3bp17u3SSy9l1KhR7mP9Vt4nJyeH3bt3Ex8fr3+fKsPuJ9Bqs8mTJ5tBQUHmpEmTzC1btpgPPPCAGR0d7fH0oVSv7Oxsc+3atebatWtNwHz11VfNtWvXmvv27TNN0zRffvllMzo62vzmm2/MDRs2mMOHDzdbtGhh5ufnu+8xZMgQs1u3buby5cvNxYsXm61btzbvvPNOu75SrfPQQw+ZUVFR5vz5883U1FT3lpeX577mwQcfNJs2bWr+9NNP5qpVq8w+ffqYffr0cbeXlJSYnTp1Mq+99lpz3bp15g8//GA2atTInDBhgh1fqVZ6+umnzQULFpjJycnmhg0bzKeffto0DMP88ccfTdPUb+TNTp3NwDT1W3mDxx9/3Jw/f76ZnJxsLlmyxBw0aJDZsGFDMz093TRN/UYXSmG2mv3jH/8wmzZtagYGBpq9evUyf/75Z7tLqlPmzZtnAmdsY8aMMU3Tmp7rmWeeMWNjY82goCBz4MCB5vbt2z3ucezYMfPOO+80w8PDzcjISPOee+4xs7Ozbfg2tVN5vw9gfvzxx+5r8vPzzYcfftisV6+eGRoaao4cOdJMTU31uM/evXvNoUOHmiEhIWbDhg3Nxx9/3CwuLq7hb1N7/epXvzKbNWtmBgYGmo0aNTIHDhzoDrKmqd/Im50eZvVb2e/222834+PjzcDAQLNx48bm7bffbu7atcvdrt/owhimaZr29AmLiIiIiFwcjZkVEREREZ+lMCsiIiIiPkthVkRERER8lsKsiIiIiPgshVkRERER8VkKsyIiIiLisxRmRURERMRnKcyKiNRRhmEwbdo0u8sQEbkoCrMiIja4++67MQzjjG3IkCF2lyYi4lP87S5ARKSuGjJkCB9//LHHuaCgIJuqERHxTeqZFRGxSVBQEHFxcR5bvXr1AGsIwDvvvMPQoUMJCQmhZcuWfPnllx7v37hxI1dffTUhISE0aNCABx54gJycHI9rPvroIzp27EhQUBDx8fGMGzfOo/3o0aOMHDmS0NBQWrduzfTp06v3S4uIVDGFWRERL/XMM89w8803s379ekaNGsUdd9zB1q1bAcjNzWXw4MHUq1ePlStXMmXKFObMmeMRVt955x3Gjh3LAw88wMaNG5k+fTqtWrXy+Iw//vGP3HbbbWzYsIHrrruOUaNGcfz48Rr9niIiF8MwTdO0uwgRkbrm7rvv5tNPPyU4ONjj/O9//3t+//vfYxgGDz74IO+884677bLLLqN79+7885//5IMPPuCpp55i//79hIWFAfD9998zbNgwDh06RGxsLI0bN+aee+7hpZdeKrcGwzD4v//7P1588UXACsjh4eHMnDlTY3dFxGdozKyIiE2uuuoqj7AKUL9+ffdxnz59PNr69OnDunXrANi6dStJSUnuIAvQr18/XC4X27dvxzAMDh06xMCBAyusoUuXLu7jsLAwIiMjSU9Pr+xXEhGpcQqzIiI2CQsLO+Ov/atKSEjIeV0XEBDg8dowDFwuV3WUJCJSLTRmVkTES/38889nvG7fvj0A7du3Z/369eTm5rrblyxZgsPhoG3btkRERNC8eXPmzp1bozWLiNQ09cyKiNiksLCQtLQ0j3P+/v40bNgQgClTpnDppZdy+eWX89lnn7FixQr+9a9/ATBq1Ciee+45xowZw/PPP8+RI0f4zW9+wy9/+UtiY2MBeP7553nwwQeJiYlh6NChZGdns2TJEn7zm9/U7BcVEalGCrMiIjb54YcfiI+P9zjXtm1btm3bBlgzDUyePJmHH36Y+Ph4/vvf/9KhQwcAQkNDmTVrFo8++ig9e/YkNDSUm2++mVdffdV9rzFjxlBQUMBrr73GE088QcOGDbnllltq7guKiNQAzWYgIuKFDMNg6tSpjBgxwu5SRES8msbMioiIiIjPUpgVEREREZ+lMbMiIl5II8BERM6PemZFRERExGcpzIqIiIiIz1KYFRERERGfpTArIiIiIj5LYVZEREREfJbCrIiIiIj4LIVZEREREfFZCrMiIiIi4rMUZkVERETEZ/0/4So4b5qwQiwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=lr,  betas=(0.9, 0.999), eps=1e-07, weight_decay=0)\n",
    "\n",
    "# Define lists to store losses\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Initialize early stopping counter \n",
    "counter = 0\n",
    "best_loss = np.inf  # Set initial loss to infinity\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(nEpoch):\n",
    "    running_loss = 0.0\n",
    "    for x_mnl, x_mlp, labels in train_loader_lmnl:\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(x_mnl,x_mlp)   \n",
    "\n",
    "        # Compute the loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running loss\n",
    "        running_loss += loss.item() # Log-likelihood on the training set\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    test_loss = evaluate_lmnl(model, loss_fn, test_loader_lmnl)\n",
    "\n",
    "    # Print status every 'status' epochs or epoch 0\n",
    "    if epoch == 0 or (epoch + 1) % status == 0:\n",
    "        print(f'Epoch [{epoch+1:5.0f}/{nEpoch}], Train Loss: {running_loss:0.3f}, Test Loss: {test_loss:0.3f}')\n",
    "\n",
    "    # Store losses\n",
    "    train_losses.append(running_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    # Implement early stopping\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch+1}')\n",
    "            break\n",
    "        \n",
    "print(f'\\nTraining finished.\\tTrain Loss: {running_loss:0.3f}, Test Loss: {test_loss:0.3f}')\n",
    "show_loss_plot(train_losses, test_losses, num_obs_train, num_obs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Willingness to pay to reduce one minute of walking time to the grocery store is: 1.22 walking minutes to the public transport\n"
     ]
    }
   ],
   "source": [
    "# Compute the Willingness to pay to reduce the distance to the grovery store by one minute\n",
    "LL_LMNL = best_loss\n",
    "B_transport_LMNL = model.B_transport.weight.data.item()\n",
    "B_stores_LMNL = model.B_stores.weight.data.item()\n",
    "\n",
    "WTP_LMNL = B_stores_LMNL/B_transport_LMNL\n",
    "print(f'\\nWillingness to pay to reduce one minute of walking time to the grocery store is: {WTP_LMNL:.2f} walking minutes to the public transport')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Reflections`\n",
    "1. The L-MNL model attains a model fit that is very close to the fully flexible MLP model\n",
    "1. The L-MNL model gives insight into the trade-off between distance to the grocery stores and distance to the public transport\n",
    "1. The results recovered WTP is not stable, it fluctuates over runs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Exercise 1: Features in MLP of LMNL model`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A` Try reducing the number of features that are feed into the MLP and assess the impact on the model performance and WTP. <br>\n",
    "E.g. only use `RESPCITY` and `WOMAN`, as in lab session 1 we saw these variables had a significant impact<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Answers`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A.i` Redefine the tensor and dimension of the MLP model to include the new variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_exercise4 = True\n",
    "if do_exercise4 == True:\n",
    "    #### Recreate tensors for the train set ####\n",
    "\n",
    "    #In this case, we only have to modify the variables that will go into the MLP model:    \n",
    "    features_socio = ['RESPCITY_2', 'RESPCITY_3', 'RESPCITY_4']\n",
    "\n",
    "    x_mlp_train = x_train_scaled[features_mlp_alt + features_socio]\n",
    "    x_mlp_test  = x_test_scaled[features_mlp_alt + features_socio]\n",
    "    \n",
    "    x_mlp_train_tensor = torch.tensor(x_mlp_train.values, dtype=torch.float)\n",
    "    x_mlp_test_tensor = torch.tensor(x_mlp_test.values, dtype=torch.float)\n",
    "    \n",
    "\n",
    "    #### Recreate DataLoader ####\n",
    "    dataset_train_lmnl = TensorDataset(x_mnl_train_tensor, x_mlp_train_tensor, y_train_dummy_tensor)\n",
    "    train_loader_lmnl = DataLoader(dataset_train_lmnl, batch_size=250, shuffle=True)\n",
    "    dataset_test_lmnl = TensorDataset(x_mnl_test_tensor, x_mlp_test_tensor, y_test_dummy_tensor)\n",
    "    test_loader_lmnl = DataLoader(dataset_test_lmnl, batch_size=len(x_mnl_test_tensor), shuffle=False)\n",
    "\n",
    "\n",
    "    #### Redefine the dimension of the MLP  ####\n",
    "    input_size_mlp = x_mlp_train_tensor.size()[1]  # Number of input features\n",
    "\n",
    "    # Invoke the L-MNL model\n",
    "    model = LMNL(input_size_mlp, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "    # -->Now Re run the previous cell to train the model with the new features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A.ii` Retrain the MLP model using the same cell as above:  <br>\n",
    "\n",
    "Train Loss: 6327.826, Test Loss: 1456.100 and the Willingness to pay to reduce one minute of walking time to the grocery store is: 0.43 walking minutes to the public transport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Exercise 2: Forecasting using L-MNL`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that a researcher would like to use this model to make forecasts for Zurich (as we did in Lab session 1). However, this is more challenging.<br>\n",
    "\n",
    "`A` Give 2 reasons why making forecasts using the L-MNL model is less straightforward than using the MNL models<br>\n",
    "`B` Give 2 arguments in favour of using the L-MNL model for informing the municipality of Zurich about the impacts of the planned redevelopment on the residential demand per neighbourhood.<br>\n",
    "`C` Suppose that you are hired to assist and advise this researcher. What would you advise in terms of e.g. the specification of the L-MNL model, training, benchmarking, etc.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Answers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A` <br>\n",
    "(1) The model makes different forecasts everytime we train it. To account for this, the researcher probably want to train numerous models and average the forecasts.<br>\n",
    "(2) In case socio-demographic variables are used, the predictions of the L-MNL model are conditional on the socio-demographic variables. In case the sample of skewed (e.g. too many females/young people, etc. it is not clear how to correct for this)<br>\n",
    "(3) Training times and data preprocessing are more time consuming and laborious<br>\n",
    "(4) The model is less easy to explain to layment than a simple MNL model. This makes adoption of the results less likely. e.g. policy makers are reluctant to base decisions on models they do not understand.<br>\n",
    "\n",
    "`B` <br>\n",
    "(1) Empirically, the L-MNL model is found to attain a considerbly better model fit. This means that the model is able to better replicate the choce behaviour, and corollary, the forecasts are more accurate.<br>\n",
    "(2) Conceptually, the linear-additive MNL model is too simplistic to captures the complexities of real human choice behaviour.<br>\n",
    "\n",
    "`C` \n",
    "- Use the MNL model to test expected interactions/nonlinearities\n",
    "- Test numerous specifications for the L-MNL, in terms of features. \n",
    "- Evaluate the specification in terms of fit, but also in terms of implied WTPs. \n",
    "- Conduct a proper hyperparameter tuning\n",
    "- Always benchmark/compare the results against the RUM-MNL. \n",
    "- Account for the stochasticity of the L-MNL model through averaging across numerous runs. \n",
    "- Ideally, new data would be collected, specifically for Zurich, that better takes into account the attributes of neighbourhoods beyond the ones used in the current SC experiment.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SEN_TORCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
