{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEN122A Statistical Analysis of Choice Behaviour \n",
    "\n",
    "## `Session Lab 03:`\n",
    "## `Combining machine learning and discrete choice models`\n",
    "\n",
    "**Delft University of Technology**<br>\n",
    "**Q2 2024**<br>\n",
    "**Instructor:** Sander van Cranenburgh<br>\n",
    "**TA:**  Gabriel Nova <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Instructions`\n",
    "\n",
    "**Lab sessions aim to:**<br>\n",
    "* Show and reinforce how models and ideas presented in class are put to practice.<br>\n",
    "* Help you gather hands-on machine learning skills.<br>\n",
    "\n",
    "**Lab sessions are:**<br>\n",
    "* Learning environments where you work with Jupyter notebooks and where you can get support from TAs and fellow students.<br> \n",
    "* Not graded and do not have to be submitted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Use of AI tools`\n",
    "AI tools, such as ChatGPT and Co-pilot, are great tools to assist with programming. Moreover, in your later careers you will work in a world where such tools are widely available. As such, we **encourage** you to use AI tools **effectively**. However, be careful not to overestimate the capacity of AI tools! AI tools cannot replace you: you still have to conceptualise the problem, dissect it and structure it, to conduct proper analysis. We recommend being especially **reticent** with using AI tools for the more conceptual and reflective oriented questions. <br>\n",
    "Futhermore, **be aware** that during the `partial exam`, you will not have acces to these tools (since internet access will be restricted)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Workspace set-up`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1: Anaconda**<br>\n",
    "\n",
    "Uncomment the following lines if you are running this notebook on your local environment and want to use ANACONDA to set up your Python environment. \n",
    "\n",
    "Please ensure that you have activated an environment that meets the Python version described in the readme file (*3.12.7, 3.11.10, or 3.10.15*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2: PIP**<br>\n",
    "Uncomment the following cell if you are running this notebook on your local environment and want to use PIP to set-up your Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 3: Google Colab**<br>\n",
    "Uncomment the following cell if you are running this notebook on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/SEN1221TUD/Q2_2024.git\n",
    "#!mv \"/content/Q2_2024/Lab_sessions/Lab_session_03/data\" /content/data   \n",
    "\n",
    "#!pip install biogeme\n",
    "#import os\n",
    "#os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Application: Modelling neighbourhood choices`\n",
    "\n",
    "In this lab session, we will use neighbourhood location choice data of lab session 1: Stated Choice (SC) data, which was collected between 2017 and 2018 in four European cities: Hanover, Mainz, Bern, and Zurich. During this lab session, you will train a neural network and a hybrid choices model to uncover people's preferences over residential location choice attributes, such as the distance to the city centre and the share of foreigners in their neighbourhood. \n",
    "\n",
    "![sc](data/sc_experiment.png)\n",
    "\n",
    "\n",
    "This time the emphesize is on the balance that the researcher must strike between behavioural rigour and model fit.\n",
    "To do so, in this lab session you will (1) develop a multilayer perceptron model and (2) build a hybrid choice models.\n",
    "\n",
    "**`Learning objectives lab session 03`**\n",
    "\n",
    "After completing the following lab session you will be able to:\n",
    "* Train a MultiLayer Perceptron on choice data\n",
    "\n",
    "\n",
    "**`This lab consists of 3 parts and has 3 exercises`**\n",
    "\n",
    "**Part 1**: Data preparation\n",
    "\n",
    "**Part 2**: The linear-additive RUM-MNL model\n",
    "- Excerise 1: \"Willigness to pay for grocery stores\"\n",
    "\n",
    "**Part 3**: The MultiLayer Perceptron\n",
    "- Excerise 2: \"Training the MLP model\"\n",
    "- Excerise 3: \"Adding the socio-demographic features\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Import packages`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biogeme\n",
    "import biogeme.database as db\n",
    "import biogeme.biogeme as bio\n",
    "from biogeme import models\n",
    "from biogeme.expressions import Beta, Variable, log\n",
    "\n",
    "# Import required Python packages and modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Pandas setting to show all columns when displaying a pandas dataframe\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `1. Load and explore the data set` <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `i. Set up the workspace and load the database`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'TASK_ID', 'STORES1', 'TRANSPORT1', 'CITY1', 'NOISE1', 'GREEN1',\n",
      "       'FOREIGN1', 'STORES2', 'TRANSPORT2', 'CITY2', 'NOISE2', 'GREEN2',\n",
      "       'FOREIGN2', 'STORES3', 'TRANSPORT3', 'CITY3', 'NOISE3', 'GREEN3',\n",
      "       'FOREIGN3', 'RESPCITY', 'WOMAN', 'AGE', 'ENVCONC', 'EDUYEARS',\n",
      "       'RESPFOREIGN', 'HOMEOWNER', 'CAROWNER', 'JOB', 'NONWESTERN', 'WESTERN',\n",
      "       'CHOICE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create that path to the data file\n",
    "data_path = Path(f'data/choice_data_cleaned.dat')\n",
    "\n",
    "# Load mode choice data into a pandas DataFrame\n",
    "df = pd.read_csv(data_path, sep='\\t')\n",
    "\n",
    "# Show the column names \n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description of variables**<br>\n",
    "\n",
    "The number concatenated to the variable refers to the alternative. Hence, `STORES1` is the column containing the attribute levels of alternative 1 for attribute STORES.<br>\n",
    "\n",
    "| Variable       | Description                                                    | Type/Levels |\n",
    "|-------------|----------------------------------------------------------------|--------------|\n",
    "| `ID`        | This is the ID number of the respondent                         | Integer      |\n",
    "| `TASK_ID`   | This is the number of the respondent's task of choice           | Integer      |\n",
    "| `STORES`    | Distance to grocery store in walking minutes                    | 2 Min., 5 Min., 10 Min., 15 Min.     |\n",
    "| `TRANSPORT` | Distance to public transportation in walking minutes            | 2 Min., 5 Min., 10 Min., 15 Min.      |\n",
    "| `CITY`      | Distance to city centre in km                                   | Below 1 km, 1 to 2 km, 3 to 4 km, over 4 km      |\n",
    "| `NOISE`     | Street traffic noise                                            | 1 = None, 2 = Little, 3 = Meduim, 4 = High      |\n",
    "| `GREEN`     | Green areas in residential area                                 | 1 = None, 2 = Few, 3 = Some, 4 = Many       |\n",
    "| `FOREIGN`   | Share of foreigners in residential areas                        | 0.10, 0.20, 0.30, 0.40     |\n",
    "| `CHOICE`    | Indicates the choice.                                           | Integer  |\n",
    "| `RESPCITY`  | Indicates the city. 1 = Mainz, 2 = Hanover, 3 = Bern, 4 = Zurich| Categorical  |\n",
    "| `WOMAN`     | Indicates 1 if woman and 0 otherwise                            | Binary       |\n",
    "| `AGE`       | Age in years                                                    | Integer      |\n",
    "| `ENVCONC`   | Environmental concern from 1 to 5, with 5 being the highest degree of concern | Ordinal |\n",
    "| `EDUYEARS`  | Number of years in education                                    | Numeric      |\n",
    "| `RESPFOREIGN`| 1 if the respondent is a foreigner, 0 otherwise                | Binary       |\n",
    "| `HOMEOWNER` | Indicates 1 if the respondent is a home owner and 0 otherwise   | Binary       |\n",
    "| `CAROWNER`  | Indicates 1 if the respondent is a car owner and 0 otherwise    | Binary       |\n",
    "| `JOB`       | 1 if the respondent is working, 0 otherwise                     | Binary       |\n",
    "| `NONWESTERN`| 1 if the respondent is non-western, 0 otherwise                 | Binary       |\n",
    "| `WESTERN`   | 1 if the respondent is western, 0 otherwise                     | Binary       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the relevant features of the alternatives\n",
    "features_alt =   ['STORES1', 'TRANSPORT1', 'CITY1', 'NOISE1', 'GREEN1', 'FOREIGN1', \n",
    "                  'STORES2', 'TRANSPORT2', 'CITY2', 'NOISE2', 'GREEN2', 'FOREIGN2',\n",
    "                  'STORES3', 'TRANSPORT3', 'CITY3', 'NOISE3', 'GREEN3', 'FOREIGN3']\n",
    "\n",
    "# Define the relevant socio-economic variables\n",
    "sociovars = ['AGE','WOMAN','HOMEOWNER','CAROWNER','RESPCITY', 'JOB','NONWESTERN', 'WESTERN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recode categorical socio demographic variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE_2</th>\n",
       "      <th>AGE_3</th>\n",
       "      <th>WOMAN_1</th>\n",
       "      <th>HOMEOWNER_1</th>\n",
       "      <th>CAROWNER_1</th>\n",
       "      <th>RESPCITY_2</th>\n",
       "      <th>RESPCITY_3</th>\n",
       "      <th>RESPCITY_4</th>\n",
       "      <th>JOB_1</th>\n",
       "      <th>NONWESTERN_1</th>\n",
       "      <th>WESTERN_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE_2  AGE_3  WOMAN_1  HOMEOWNER_1  CAROWNER_1  RESPCITY_2  RESPCITY_3  \\\n",
       "0      1      0        0            0           0           0           1   \n",
       "1      1      0        0            0           0           0           1   \n",
       "2      1      0        0            0           0           0           1   \n",
       "3      1      0        0            0           0           0           1   \n",
       "4      1      0        1            0           1           1           0   \n",
       "\n",
       "   RESPCITY_4  JOB_1  NONWESTERN_1  WESTERN_1  \n",
       "0           0      0             0          0  \n",
       "1           0      0             0          0  \n",
       "2           0      0             0          0  \n",
       "3           0      0             0          0  \n",
       "4           0      1             0          0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe with the relevant socio demographic variables\n",
    "df_sociovars  = df[sociovars].astype(int)\n",
    "\n",
    "# Recode 'AGE' in three categorical levels.\n",
    "df_sociovars.loc[(      df_sociovars['AGE'] < 25), 'AGE'] = 1\n",
    "df_sociovars.loc[(25 <= df_sociovars['AGE']     ) &\n",
    "                 (      df_sociovars['AGE'] < 60), 'AGE'] = 2\n",
    "df_sociovars.loc[(60 <= df_sociovars['AGE']     ), 'AGE'] = 3\n",
    "\n",
    "# Convert categorical variables to dummy variables using pd.get_dummies()\n",
    "df_sociovars = pd.get_dummies(data = df_sociovars, prefix = sociovars, prefix_sep='_', columns = sociovars, drop_first = True, dtype=int)\n",
    "\n",
    "# Create a list of the names of the socio demographic variables\n",
    "features_socio = df_sociovars.columns.tolist()\n",
    "\n",
    "# Show the first few rows of the dataframe\n",
    "df_sociovars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create the dataframe for training, containing the 'ID', 'CHOICE', attributes and dummy-coded socio-demographic variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CHOICE</th>\n",
       "      <th>STORES1</th>\n",
       "      <th>TRANSPORT1</th>\n",
       "      <th>CITY1</th>\n",
       "      <th>NOISE1</th>\n",
       "      <th>GREEN1</th>\n",
       "      <th>FOREIGN1</th>\n",
       "      <th>STORES2</th>\n",
       "      <th>TRANSPORT2</th>\n",
       "      <th>CITY2</th>\n",
       "      <th>NOISE2</th>\n",
       "      <th>GREEN2</th>\n",
       "      <th>FOREIGN2</th>\n",
       "      <th>STORES3</th>\n",
       "      <th>TRANSPORT3</th>\n",
       "      <th>CITY3</th>\n",
       "      <th>NOISE3</th>\n",
       "      <th>GREEN3</th>\n",
       "      <th>FOREIGN3</th>\n",
       "      <th>AGE_2</th>\n",
       "      <th>AGE_3</th>\n",
       "      <th>WOMAN_1</th>\n",
       "      <th>HOMEOWNER_1</th>\n",
       "      <th>CAROWNER_1</th>\n",
       "      <th>RESPCITY_2</th>\n",
       "      <th>RESPCITY_3</th>\n",
       "      <th>RESPCITY_4</th>\n",
       "      <th>JOB_1</th>\n",
       "      <th>NONWESTERN_1</th>\n",
       "      <th>WESTERN_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  CHOICE  STORES1  TRANSPORT1  CITY1  NOISE1  GREEN1  FOREIGN1  STORES2  \\\n",
       "0   2       1       10           5      1       2       2       0.4       15   \n",
       "1   2       2       15           5      4       4       1       0.1        2   \n",
       "2   2       3       10          15      1       3       1       0.4       15   \n",
       "3   2       2       15          15      5       4       4       0.4        2   \n",
       "4   3       2       15           5      5       1       3       0.4        2   \n",
       "\n",
       "   TRANSPORT2  CITY2  NOISE2  GREEN2  FOREIGN2  STORES3  TRANSPORT3  CITY3  \\\n",
       "0          10      2       3       3       0.1        2          15      4   \n",
       "1          10      5       1       2       0.2        5          15      1   \n",
       "2           2      2       4       2       0.1        2           5      4   \n",
       "3           2      1       1       1       0.1        5           5      2   \n",
       "4          10      1       2       4       0.1        5          15      2   \n",
       "\n",
       "   NOISE3  GREEN3  FOREIGN3  AGE_2  AGE_3  WOMAN_1  HOMEOWNER_1  CAROWNER_1  \\\n",
       "0       4       4       0.2      1      0        0            0           0   \n",
       "1       2       3       0.3      1      0        0            0           0   \n",
       "2       1       3       0.2      1      0        0            0           0   \n",
       "3       2       2       0.2      1      0        0            0           0   \n",
       "4       3       1       0.2      1      0        1            0           1   \n",
       "\n",
       "   RESPCITY_2  RESPCITY_3  RESPCITY_4  JOB_1  NONWESTERN_1  WESTERN_1  \n",
       "0           0           1           0      0             0          0  \n",
       "1           0           1           0      0             0          0  \n",
       "2           0           1           0      0             0          0  \n",
       "3           0           1           0      0             0          0  \n",
       "4           1           0           0      1             0          0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the socio demographic variables with the relevant features of the alternatives\n",
    "df = pd.concat([df[['ID', 'CHOICE'] + features_alt], df_sociovars], axis=1)\n",
    "\n",
    "# Show the first few rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ii. Split the data in a test and train set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of individuals in the df_train and df_test: \t1825  423 \n",
      "Number of observations in the df_train and df_test: \t7300 1692 \n"
     ]
    }
   ],
   "source": [
    "# Set a seed for reproducibilty\n",
    "np.random.seed(100)\n",
    "df['draw']=float('nan')\n",
    "for i in df['ID'].unique():\n",
    "    num_obs = len(df.loc[df['ID']==i,'draw'])\n",
    "    df.loc[df['ID']==i,'draw']= np.repeat(np.random.uniform(0,1,1),num_obs)\n",
    "\n",
    "# Put 80% of the data in the training set and 20% in the test set\n",
    "df_train = df.loc[df['draw']< 0.8,:].copy()\n",
    "df_test  = df.loc[df['draw']>=0.8,:].copy()\n",
    "\n",
    "# Number of observations in the training and test sets\n",
    "num_obs_train = len(df_train)\n",
    "num_obs_test  = len(df_test)\n",
    "\n",
    "print(f'Number of individuals in the df_train and df_test: \\t{df_train.ID.nunique()}  {df_test.ID.nunique()} ')\n",
    "print(f'Number of observations in the df_train and df_test: \\t{len(df_train)} {len(df_test)} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a copy of the dataset for use in Lab 03EXTRA\n",
    "df['train_set'] = df['draw']<0.8\n",
    "df['test_set'] = df['draw']>=0.8\n",
    "\n",
    "# Save the dataset to a file\n",
    "df.to_csv('data/choice_data_cleaned_lab3E.dat', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iii. Scaling the features`<br>\n",
    "To efficiently train ANNs it strongly recommended to scale (a.k.a. normalise) the features. There are several ways to scale your data. A commonly used scaler of sk-learn is called 'StandardScaler'. This scaler normalises the variance and shift the location of the distribution to zero, see https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train (7300, 29)\n",
      "Shape of x_test (1692, 29)\n"
     ]
    }
   ],
   "source": [
    "# Create X_train and X_test\n",
    "x_train = df_train[features_alt + features_socio]\n",
    "x_test  = df_test [features_alt + features_socio]\n",
    "\n",
    "# Initialize the scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "scaler = scaler.fit(df[features_alt + features_socio])\n",
    "\n",
    "# Apply the fitted scaler to the  data sets\n",
    "x_train_scaled = pd.DataFrame(scaler.transform(df_train[features_alt + features_socio]), columns=[features_alt + features_socio])\n",
    "x_test_scaled =  pd.DataFrame(scaler.transform(df_test [features_alt + features_socio]), columns=[features_alt + features_socio]) # Apply the fitted scaler to the test data\n",
    "\n",
    "print('Shape of x_train', x_train_scaled.shape)\n",
    "print('Shape of x_test', x_test_scaled.shape)\n",
    "\n",
    "# Create the target values\n",
    "# Y must be a dummy coded array\n",
    "y_train_dummy = pd.get_dummies(df_train['CHOICE']).values.astype(int)\n",
    "y_test_dummy = pd.get_dummies(df_test['CHOICE']).values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iv. Conversion to tensors`<br>\n",
    "Many machine learning packages work with so-called tensors. Tensors are dedicated data structures to effciently train neural networks. Therefore, we need to convert the features and the target into a tensors datatype. In PyTorch, this is done with `torch.tensor()`.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train_tensor\t torch.Size([7300, 18])\n",
      "Shape of x_test_tensor\t torch.Size([1692, 18])\n"
     ]
    }
   ],
   "source": [
    "# Create tensors for the train set\n",
    "# In this case, we use only the features of the alternatives 'features_alt'\n",
    "x_train_tensor = torch.tensor(x_train_scaled[features_alt].values, dtype=torch.float)\n",
    "y_train_dummy_tensor = torch.tensor(y_train_dummy, dtype=torch.float)\n",
    "\n",
    "# Create tensors for the test set\n",
    "x_test_tensor = torch.tensor(x_test_scaled[features_alt].values, dtype=torch.float)\n",
    "y_test_dummy_tensor = torch.tensor(y_test_dummy, dtype=torch.float)\n",
    "\n",
    "# Print the shapes of the tensors   \n",
    "print('Shape of x_train_tensor\\t', x_train_tensor.shape)\n",
    "print('Shape of x_test_tensor\\t', x_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `2. Linear-additive RUM-MNL benchmark model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`i. Model estimation`<br>\n",
    "We first estimate our a linear-addtive RUM-MNL benchmark model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pandas df into biogeme database\n",
    "biodata_train = db.Database('neighbourhood_data_train', df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Biogeme variables\n",
    "\n",
    "# Attributes of alternative 1\n",
    "STORES1     = Variable('STORES1')\n",
    "TRANSPORT1  = Variable('TRANSPORT1')\n",
    "CITY1       = Variable('CITY1')\n",
    "NOISE1      = Variable('NOISE1')\n",
    "GREEN1      = Variable('GREEN1')\n",
    "FOREIGN1    = Variable('FOREIGN1')\n",
    "\n",
    "# Attributes of alternative 2    \n",
    "STORES2     = Variable('STORES2')\n",
    "TRANSPORT2  = Variable('TRANSPORT2')\n",
    "CITY2       = Variable('CITY2')\n",
    "NOISE2      = Variable('NOISE2')\n",
    "GREEN2      = Variable('GREEN2')\n",
    "FOREIGN2    = Variable('FOREIGN2')\n",
    "    \n",
    "# Attributes of alternative 3\n",
    "STORES3     = Variable('STORES3')\n",
    "TRANSPORT3  = Variable('TRANSPORT3')\n",
    "CITY3       = Variable('CITY3')\n",
    "NOISE3      = Variable('NOISE3')\n",
    "GREEN3      = Variable('GREEN3')\n",
    "FOREIGN3    = Variable('FOREIGN3')\n",
    "\n",
    "# choice\n",
    "CHOICE      = Variable('CHOICE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model Linear-additive RUM-MNL\n",
      "Nbr of parameters:\t\t6\n",
      "Sample size:\t\t\t7300\n",
      "Excluded data:\t\t\t0\n",
      "Null log likelihood:\t\t-8019.87\n",
      "Final log likelihood:\t\t-6511.05\n",
      "Likelihood ratio test (null):\t\t3017.64\n",
      "Rho square (null):\t\t\t0.188\n",
      "Rho bar square (null):\t\t\t0.187\n",
      "Akaike Information Criterion:\t13034.1\n",
      "Bayesian Information Criterion:\t13075.47\n",
      "\n",
      "                Value  Rob. Std err  Rob. t-test  Rob. p-value\n",
      "B_city      -0.163189      0.009138   -17.857614           0.0\n",
      "B_foreign   -1.223319      0.124067    -9.860112           0.0\n",
      "B_green      0.412454      0.012934    31.889392           0.0\n",
      "B_noise     -0.433723      0.011975   -36.219826           0.0\n",
      "B_stores    -0.033651      0.002956   -11.383961           0.0\n",
      "B_transport -0.073372      0.002823   -25.989810           0.0\n"
     ]
    }
   ],
   "source": [
    "# Give a name to the model    \n",
    "model_name = 'Linear-additive RUM-MNL'\n",
    "\n",
    "# Define the model parameters, using the function \"Beta()\", in which you must define:\n",
    "B_stores    = Beta('B_stores'   , 0, None, None, 0)\n",
    "B_transport = Beta('B_transport', 0, None, None, 0)\n",
    "B_city      = Beta('B_city'     , 0, None, None, 0)\n",
    "B_noise     = Beta('B_noise'    , 0, None, None, 0)\n",
    "B_green     = Beta('B_green'    , 0, None, None, 0)\n",
    "B_foreign   = Beta('B_foreign'  , 0, None, None, 0)\n",
    "\n",
    "# Define the utility functions\n",
    "V1 = B_stores * STORES1 + B_transport * TRANSPORT1 + B_city * CITY1 + B_noise * NOISE1 + B_green * GREEN1 + B_foreign * FOREIGN1\n",
    "V2 = B_stores * STORES2 + B_transport * TRANSPORT2 + B_city * CITY2 + B_noise * NOISE2 + B_green * GREEN2 + B_foreign * FOREIGN2\n",
    "V3 = B_stores * STORES3 + B_transport * TRANSPORT3 + B_city * CITY3 + B_noise * NOISE3 + B_green * GREEN3 + B_foreign * FOREIGN3\n",
    "\n",
    "# Associate utility functions with alternatives\n",
    "V = {1: V1, 2: V2, 3: V3}    \n",
    "\n",
    "# Associate the availability conditions with the alternatives\n",
    "AV = {1: 1, 2: 1, 3: 1} \n",
    "\n",
    "# Definition of the model. This is the contribution of each observation to the log likelihood function.\n",
    "prob = models.logit(V, AV, CHOICE)\n",
    "\n",
    "# Create the Biogeme object\n",
    "biogeme = bio.BIOGEME(biodata_train, log(prob))\n",
    "\n",
    "# Set reporting levels\n",
    "biogeme.generate_pickle = False\n",
    "biogeme.generate_html = False\n",
    "biogeme.saveIterations = False\n",
    "biogeme.modelName = model_name\n",
    "\n",
    "# Compute the null loglikelihood for reporting\n",
    "biogeme.calculate_null_loglikelihood(AV)\n",
    "\n",
    "# Estimate the parameters\n",
    "results = biogeme.estimate()\n",
    "print(results.short_summary())\n",
    "\n",
    "# Get the results in a pandas table\n",
    "beta_hat = results.get_estimated_parameters()\n",
    "print(beta_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ii. Compute the LL of the estimated model on the test set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LL MNL test: -1472.97\n"
     ]
    }
   ],
   "source": [
    "# Create the biogeme simulation object\n",
    "biodate_test = db.Database('Neighbourhood_data_test', df_test)\n",
    "\n",
    "# Simulate th choice probability for the MNL model on the test set\n",
    "dict2simulate = {'prob_chosen':prob}\n",
    "\n",
    "# Create the Biogeme simulation object\n",
    "biosim = bio.BIOGEME(biodate_test,dict2simulate)\n",
    "simulated_probs = biosim.simulate(the_beta_values=results.get_beta_values())\n",
    "\n",
    "# Calculate the log-likelihood of the MNL model on the test set and print it\n",
    "LL_MNL_test = np.log(simulated_probs['prob_chosen']).sum()\n",
    "print(f'LL MNL test: {LL_MNL_test:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``Exercise 1: Willingness to pay for grocery stores``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A` Calculate the willingness to pay reduce the number of walking minutes to the grocery stores by one minute, expressed in terms of walking minutes to the public transport. Use formula:<br><br>\n",
    "$WTP = \\frac{\\beta_{stores}}{\\beta_{transport}}$<br><br>\n",
    "`B` Interpret this result. What do people find more important; walking minutes to grocery stores or walking minutes to public transport?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Answers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Willigness to pay to reduce one minute of walking time to the grocery store is: 0.46 walking minutes to the public transport\n",
      "\n",
      "Distance to the public transport almost twice as important than distance to the grocery store because the WTP is < 1\n"
     ]
    }
   ],
   "source": [
    "# A\n",
    "WTP_MNL = beta_hat.loc['B_stores']['Value']/beta_hat.loc['B_transport']['Value']\n",
    "print(f'\\nWilligness to pay to reduce one minute of walking time to the grocery store is: {WTP_MNL:.2f} walking minutes to the public transport')\n",
    "\n",
    "# B\n",
    "print('\\nDistance to the public transport almost twice as important than distance to the grocery store because the WTP is < 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `3. The MLP model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A MultiLayer Perceptron (MLP) is a neural network widely used in machine learning because of its ability to learn complex patterns. It is composed of hidden layers with neurons and activation functions. <br>\n",
    "\n",
    "For example, in the following image, we can see an input layer with 8 features, two hidden layers with each 10 hidden nodes, and the output layer with 3 output classes:<br>\n",
    "\n",
    "<p align=\"center\\\">\n",
    "<img width=\"800\" src=\"assets/MLP.png\">\n",
    "</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`i. Define MLP model`<br>\n",
    "We will create a fully connected neural network with two hidden layers. To do so, we create a new class using PyTorch's nn.Module. We define how the object is initialised.In this case, we will have an input layer of size `input_size`, two hidden layers with sizes `hidden_size1` and `hidden_size2` respectively, and an output layer of size `output_size`. Additionally, we define the forward function. The forward function takes an input value `x`, passes it through the network layers, while applying activation functions. It outputs the utilities of each alternative `V`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with two hidden layer\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x)) # tanh activation function for the 1st layer\n",
    "        x = torch.tanh(self.fc2(x)) # tanh activation function for the 2nd layer\n",
    "        V = self.fc3(x)             # linear activation function for the output layer\n",
    "\n",
    "        return V                    # return the \"Utility\" of each alternative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ii. Create DataLoaders`<br>\n",
    "A PyTorch Dataloader object effciently handles the data flow during training and testing. It creates the minibatches, and ensures that are instances of the data are depleted each epoch. <br>We create a DataLoader for both the train and test data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader for the train set\n",
    "dataset_train = TensorDataset(x_train_tensor, y_train_dummy_tensor)\n",
    "train_loader = DataLoader(dataset_train, batch_size=250, shuffle=True)\n",
    "\n",
    "# Create a DataLoader for the test set\n",
    "dataset_test = TensorDataset(x_test_tensor, y_test_dummy_tensor)\n",
    "test_loader = DataLoader(dataset_test, batch_size=len(x_test_tensor), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iii. Define functions`<br>\n",
    "We define the the following functions:\n",
    "1. a function to evaluate the model performance during training\n",
    "2. a function to visualise the training progress\n",
    "3. a function to inspect the model object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is used to evaluate the performance on the test data after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, data_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function visualises the training progress. We call this function after the training is finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_loss_plot(train_losses, test_losses, num_obs_train, num_obs_test):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.plot(np.array(train_losses)/num_obs_train, label='Training Loss')\n",
    "    ax.plot(np.array(test_losses)/num_obs_test,   label='Test Loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function allows us to inspect the created model architecture. It lists the number of weights per layer, and their input and output sizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_summary(model):\n",
    "    total_params = 0\n",
    "    print(f\"=== Model Summary ===\")\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            num_params = param.numel()\n",
    "            total_params += num_params\n",
    "            print(f\"Layer: {name:20}|\\t Weights: {num_params}\")\n",
    "\n",
    "    print(f\"\\nTotal trainable Weights: {total_params}\")\n",
    "\n",
    "    print(\"\\n=== Layers ===\")\n",
    "    for layer in model.children():\n",
    "        print(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iv. Create the MLP object`<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input_size = 18, hidden_size1 = 20, hidden_size2 = 20, output_size = 3\n"
     ]
    }
   ],
   "source": [
    "# Define the dimensions of the MLP\n",
    "input_size   = x_train_tensor.size()[1]  # Number of input features\n",
    "hidden_size1 = 20#0                        # Number of units in first hidden layer\n",
    "hidden_size2 = 20#0                        # Number of units in second hidden layer\n",
    "output_size  = 3                         # Number of output classes (determined by the number of alternatives)\n",
    "print(f' input_size = {input_size}, hidden_size1 = {hidden_size1}, hidden_size2 = {hidden_size2}, output_size = {output_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Summary ===\n",
      "Layer: fc1.weight          |\t Weights: 360\n",
      "Layer: fc1.bias            |\t Weights: 20\n",
      "Layer: fc2.weight          |\t Weights: 400\n",
      "Layer: fc2.bias            |\t Weights: 20\n",
      "Layer: fc3.weight          |\t Weights: 60\n",
      "Layer: fc3.bias            |\t Weights: 3\n",
      "\n",
      "Total trainable Weights: 863\n",
      "\n",
      "=== Layers ===\n",
      "Linear(in_features=18, out_features=20, bias=True)\n",
      "Linear(in_features=20, out_features=20, bias=True)\n",
      "Linear(in_features=20, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# Invoke the MLP model\n",
    "model = MLP(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Print the model architecture\n",
    "print_model_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define settings for the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`v. Train the MLP model`<br>\n",
    "Finally, we are ready to train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "nEpoch = 500  # Set the number of epochs\n",
    "lr = 0.0001  # Set the learning rate\n",
    "status = 10  # Print status every 'status' epochs\n",
    "patience = 5  # Number of epochs to wait before early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [    1/500], Train Loss: 7965.256, Test Loss: 1836.607\n",
      "Epoch [   10/500], Train Loss: 7431.839, Test Loss: 1713.368\n",
      "Epoch [   20/500], Train Loss: 6750.208, Test Loss: 1553.916\n",
      "Epoch [   30/500], Train Loss: 6357.026, Test Loss: 1459.596\n",
      "Epoch [   40/500], Train Loss: 6189.051, Test Loss: 1418.405\n",
      "Epoch [   50/500], Train Loss: 6120.141, Test Loss: 1401.700\n",
      "Epoch [   60/500], Train Loss: 6090.310, Test Loss: 1394.954\n",
      "Epoch [   70/500], Train Loss: 6075.886, Test Loss: 1391.769\n",
      "Epoch [   80/500], Train Loss: 6067.653, Test Loss: 1389.749\n",
      "Epoch [   90/500], Train Loss: 6062.271, Test Loss: 1388.734\n",
      "Epoch [  100/500], Train Loss: 6058.379, Test Loss: 1387.761\n",
      "Epoch [  110/500], Train Loss: 6055.516, Test Loss: 1387.259\n",
      "Epoch [  120/500], Train Loss: 6053.473, Test Loss: 1386.862\n",
      "Early stopping at epoch 123\n",
      "\n",
      "Training finished.\tTrain Loss: 6053.136, Test Loss: 1386.848\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "do_training = True\n",
    "if do_training == True:\n",
    "\n",
    "    # Define the model, loss function and optimizer\n",
    "    \n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=lr,  betas=(0.9, 0.999), eps=1e-07, weight_decay=0)\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "    # Define lists to store losses\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    # Initialize early stopping counter \n",
    "    counter = 0\n",
    "    best_loss = np.inf  # Set initial loss to infinity\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(nEpoch):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)   \n",
    "\n",
    "            # Compute the loss\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update running loss\n",
    "            running_loss += loss.item() # Log-likelihood on the training set\n",
    "\n",
    "        # Evaluate on the test set\n",
    "        test_loss = evaluate(model, loss_fn, test_loader) # Log-likelihood on the test set\n",
    "\n",
    "        # Print status every 'status' epochs or epoch 0\n",
    "        if epoch == 0 or (epoch + 1) % status == 0:\n",
    "            print(f'Epoch [{epoch+1:5.0f}/{nEpoch}], Train Loss: {running_loss:0.3f}, Test Loss: {test_loss:0.3f}')\n",
    "\n",
    "        # Store losses\n",
    "        train_losses.append(running_loss)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        # Implement early stopping\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(f'Early stopping at epoch {epoch+1}')\n",
    "                break\n",
    "            \n",
    "    print(f'\\nTraining finished.\\tTrain Loss: {running_loss:0.3f}, Test Loss: {test_loss:0.3f}')\n",
    "    show_loss_plot(train_losses, test_losses,num_obs_train, num_obs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Exercise 2: Training the MLP model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A` Compare the performance on the test set of the MLP with the benchmark MNL. Has it (much) improved? What does this tell us? <br>\n",
    "`B` Retrain the MLP using the following architectures: {hidden_size1,hidden_size2} = {1,1}, {3,3}, {1,20}, {20,1}, {20,3}, {20,20}<br>\n",
    "`C` Does increasing the number of nodes lead to better generalisation performance (i.e. higher LL_test)? What is happening?<br>\n",
    "`D` Explain why {1,1} and either {20,1} and {1,20} lead to a poor performance. <br>\n",
    "`E` Retrain your model with a smaller and larger learning rate: lr = 0.01 and lr = 0.00001. Use {hidden_size1,hidden_size2} = {5,5}. Explain what is happening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Answers`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A` The MLP improves the model fit by  almost 100 LL points. This is a lot. It tells the linear-additive utility assumption is too restrictive.<br>\n",
    "\n",
    "`B`<br>\n",
    "{1,1} gives a poor generalisation performance: LL = ~-1670<br>\n",
    "{3,3} gives an okay generalisation performance: LL = ~-1470<br>\n",
    "{1,20} gives a poor generalisation performance: LL = ~-1630<br>\n",
    "{20,1} gives an poor generalisation performance: LL = ~-1670<br>\n",
    "{20,3} gives an okay generalisation performance: LL = ~-1457<br>\n",
    "{20,20} gives an okay generalisation performance: LL = ~-1455<br>\n",
    "\n",
    "`C` Increasing it from {1,1} to {3,3} increase the perf on LL_test. But {20,20} does not help it to further increase. <br>\n",
    "\n",
    "`D` All information is squashed to one node. Therefore, the models is not able to associate features to alternatives, leading to a poor performance.<br>\n",
    "\n",
    "`E` A large lr leads to quick training. But instability near the convergence. A small lr leads to slow training. The model was not nearly converged when the maximum number of training epochs was reached. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Exercise 3: Adding the socio-demographic features`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Section 1 under `iv. Conversion to tensors` we choose to use only the features of the alternatives as inputs (i.e. `features_alt`), while in lab session 1 we saw that at least gender (`WOMAN`) and the residential city (`RESPCITY`) have some eplanatory power.<br>\n",
    "\n",
    "`A` Modify the code in this cell so that also these socio demographic features are used. Then, retrain the MLP.<br>\n",
    "`B` Perhaps counter to your expectations, the model performance does not increase much. \n",
    "What does this tell us about: \n",
    "1. the explanatory power of socio-demographics to the residential location choice, and \n",
    "2. the ability of MLP models to learn subtle interaction effects? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Answers`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A.i` Redefine the tensor and dimension of the MLP model to include the new variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_exercise3 = False\n",
    "if do_exercise3 == True:\n",
    "    #### Recreate tensors for the train set ####\n",
    "\n",
    "    # In this case, we use the characteristics of the alternatives 'features_alt', WOMAN and RESPCITY.\n",
    "    selected_features = features_alt + ['WOMAN_1', 'RESPCITY_2', 'RESPCITY_3', 'RESPCITY_4']\n",
    "\n",
    "    x_train_tensor = torch.tensor(x_train_scaled[selected_features].values, dtype=torch.float)\n",
    "    y_train_dummy_tensor = torch.tensor(y_train_dummy, dtype=torch.float)\n",
    "\n",
    "    x_test_tensor = torch.tensor(x_test_scaled[selected_features].values, dtype=torch.float)\n",
    "    y_test_dummy_tensor = torch.tensor(y_test_dummy, dtype=torch.float)\n",
    "\n",
    "    #### Recreate DataLoader ####\n",
    "    dataset_train = TensorDataset(x_train_tensor, y_train_dummy_tensor)\n",
    "    train_loader = DataLoader(dataset_train, batch_size=250, shuffle=True)\n",
    "\n",
    "    dataset_test = TensorDataset(x_test_tensor, y_test_dummy_tensor)\n",
    "    test_loader = DataLoader(dataset_test, batch_size=len(x_test_tensor), shuffle=True)\n",
    "\n",
    "    #### Redefine the dimension of the MLP  ####\n",
    "    input_size   = x_train_tensor.size()[1]  # Number of input features\n",
    "    hidden_size1 = 20                        # Number of units in first hidden layer\n",
    "    hidden_size2 = 20                        # Number of units in second hidden layer\n",
    "    output_size  = 3                         # Number of output classes (determined by the number of alternatives)\n",
    "\n",
    "    model = MLP(input_size, hidden_size1, hidden_size2, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A.ii` Retrain the MLP model using the same cell as above:  <br>\n",
    "\n",
    "Train Loss: 6376.556, Test Loss: 1454.600<br> \n",
    "\n",
    "\n",
    "`B.1` The slight improvement in the performance of the MLP model by including the WOMAN and RESPCITY variables suggests that these socio-demographic factors may not be key determinants of residential choice. <br>\n",
    "\n",
    "`B.2` Furthermore, this suggests that MLP models may have difficulty capturing small relationships between factors, which highlights the importance of adequately considering the features included in the model estimation. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SEN_TORCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
